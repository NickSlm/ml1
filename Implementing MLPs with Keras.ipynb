{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96eaf858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7738f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8734c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1318f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b51961",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d10507",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51897a",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24d59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden_1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden_2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286301b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdebc8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7767 - val_loss: 12.9986\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.7627 - val_loss: 0.6218\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.6061 - val_loss: 0.6448\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.5770 - val_loss: 0.5414\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 935us/step - loss: 0.5514 - val_loss: 0.5247\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.5299 - val_loss: 0.5118\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.5128 - val_loss: 0.5089\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.4991 - val_loss: 0.4954\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 957us/step - loss: 0.4848 - val_loss: 0.4635\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.4735 - val_loss: 0.4576\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 942us/step - loss: 0.4642 - val_loss: 0.5017\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 943us/step - loss: 0.4550 - val_loss: 0.4620\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4484 - val_loss: 0.4248\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4410 - val_loss: 0.4140\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.4351 - val_loss: 0.4149\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 910us/step - loss: 0.4298 - val_loss: 0.4037\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.4255 - val_loss: 0.4250\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.4211 - val_loss: 0.4167\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4168 - val_loss: 0.3930\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.4269\n",
      "162/162 [==============================] - 0s 668us/step - loss: 0.4075\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f1c571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40746474266052246"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114d4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_b = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden_1 = keras.layers.Dense(30, activation=\"relu\")(input_b)\n",
    "hidden_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "conc = keras.layers.Concatenate()([input_a, hidden_2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(conc)\n",
    "model = keras.Model(inputs=[input_a, input_b], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59ccc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.0125 - val_loss: 0.8598\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.7278 - val_loss: 0.6542\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.6458 - val_loss: 0.6060\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6091 - val_loss: 0.5615\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.5835 - val_loss: 0.5374\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.5614 - val_loss: 0.5150\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5442 - val_loss: 0.5006\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.5291 - val_loss: 0.4861\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.5157 - val_loss: 0.4725\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.5044 - val_loss: 0.4616\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.4950 - val_loss: 0.4745\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4867 - val_loss: 0.4454\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.4800 - val_loss: 0.4515\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4739 - val_loss: 0.4377\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4684 - val_loss: 0.4485\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.4634 - val_loss: 0.4282\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4587 - val_loss: 0.4365\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4371\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4213\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.4468 - val_loss: 0.4630\n",
      "162/162 [==============================] - 0s 674us/step - loss: 0.4388\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_val_A, X_val_B = X_val[:,:5], X_val[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_val_A, X_val_B), y_val))\n",
    "mse_test = model.evaluate((X_test_A,X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee426f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\") \n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden_1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "concat = keras.layers.Concatenate()([hidden_1, input_A])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux = keras.layers.Dense(1, name=\"Aux_output\")(hidden_2)\n",
    "\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux])\n",
    "model.compile(loss=[\"mse\",\"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdedc42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.9620 - main_output_loss: 2.6077 - Aux_output_loss: 6.1509 - val_loss: 1.9989 - val_main_output_loss: 1.6752 - val_Aux_output_loss: 4.9127\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2129 - main_output_loss: 0.9095 - Aux_output_loss: 3.9433 - val_loss: 1.2201 - val_main_output_loss: 0.8097 - val_Aux_output_loss: 4.9141\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9029 - main_output_loss: 0.7021 - Aux_output_loss: 2.7104 - val_loss: 1.1281 - val_main_output_loss: 0.6592 - val_Aux_output_loss: 5.3481\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7802 - main_output_loss: 0.6384 - Aux_output_loss: 2.0567 - val_loss: 1.0741 - val_main_output_loss: 0.6102 - val_Aux_output_loss: 5.2492\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7117 - main_output_loss: 0.6019 - Aux_output_loss: 1.7006 - val_loss: 0.9876 - val_main_output_loss: 0.5759 - val_Aux_output_loss: 4.6925\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6683 - main_output_loss: 0.5760 - Aux_output_loss: 1.4996 - val_loss: 0.8922 - val_main_output_loss: 0.5564 - val_Aux_output_loss: 3.9142\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6369 - main_output_loss: 0.5551 - Aux_output_loss: 1.3738 - val_loss: 0.8106 - val_main_output_loss: 0.5395 - val_Aux_output_loss: 3.2507\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6141 - main_output_loss: 0.5389 - Aux_output_loss: 1.2907 - val_loss: 0.7303 - val_main_output_loss: 0.5131 - val_Aux_output_loss: 2.6857\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5955 - main_output_loss: 0.5247 - Aux_output_loss: 1.2329 - val_loss: 0.6702 - val_main_output_loss: 0.4990 - val_Aux_output_loss: 2.2117\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5806 - main_output_loss: 0.5131 - Aux_output_loss: 1.1876 - val_loss: 0.6214 - val_main_output_loss: 0.4883 - val_Aux_output_loss: 1.8195\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5683 - main_output_loss: 0.5035 - Aux_output_loss: 1.1514 - val_loss: 0.5827 - val_main_output_loss: 0.4751 - val_Aux_output_loss: 1.5519\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5580 - main_output_loss: 0.4954 - Aux_output_loss: 1.1219 - val_loss: 0.5558 - val_main_output_loss: 0.4668 - val_Aux_output_loss: 1.3575\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5492 - main_output_loss: 0.4885 - Aux_output_loss: 1.0961 - val_loss: 0.5359 - val_main_output_loss: 0.4590 - val_Aux_output_loss: 1.2280\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5415 - main_output_loss: 0.4825 - Aux_output_loss: 1.0727 - val_loss: 0.5223 - val_main_output_loss: 0.4526 - val_Aux_output_loss: 1.1493\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5348 - main_output_loss: 0.4773 - Aux_output_loss: 1.0516 - val_loss: 0.5123 - val_main_output_loss: 0.4479 - val_Aux_output_loss: 1.0917\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5288 - main_output_loss: 0.4728 - Aux_output_loss: 1.0321 - val_loss: 0.5032 - val_main_output_loss: 0.4428 - val_Aux_output_loss: 1.0469\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5236 - main_output_loss: 0.4691 - Aux_output_loss: 1.0134 - val_loss: 0.4962 - val_main_output_loss: 0.4388 - val_Aux_output_loss: 1.0119\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5186 - main_output_loss: 0.4656 - Aux_output_loss: 0.9954 - val_loss: 0.4921 - val_main_output_loss: 0.4375 - val_Aux_output_loss: 0.9833\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5137 - main_output_loss: 0.4621 - Aux_output_loss: 0.9781 - val_loss: 0.4857 - val_main_output_loss: 0.4330 - val_Aux_output_loss: 0.9605\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5097 - main_output_loss: 0.4595 - Aux_output_loss: 0.9612 - val_loss: 0.4850 - val_main_output_loss: 0.4343 - val_Aux_output_loss: 0.9414\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_val_A, X_val_B], [y_val,y_val]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ec9f1",
   "metadata": {},
   "source": [
    "# Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcfdfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41674af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel(units=30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b5ea0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.1362 - output_1_loss: 1.8201 - output_2_loss: 4.9810 - val_loss: 3.2150 - val_output_1_loss: 2.9510 - val_output_2_loss: 5.5911\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9772 - output_1_loss: 0.7419 - output_2_loss: 3.0944 - val_loss: 1.5983 - val_output_1_loss: 1.0903 - val_output_2_loss: 6.1704\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7844 - output_1_loss: 0.6266 - output_2_loss: 2.2041 - val_loss: 1.1590 - val_output_1_loss: 0.6030 - val_output_2_loss: 6.1629\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7000 - output_1_loss: 0.5712 - output_2_loss: 1.8591 - val_loss: 1.0323 - val_output_1_loss: 0.5276 - val_output_2_loss: 5.5747\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6501 - output_1_loss: 0.5343 - output_2_loss: 1.6916 - val_loss: 0.9293 - val_output_1_loss: 0.4939 - val_output_2_loss: 4.8475\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6161 - output_1_loss: 0.5077 - output_2_loss: 1.5918 - val_loss: 0.8465 - val_output_1_loss: 0.4762 - val_output_2_loss: 4.1797\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5922 - output_1_loss: 0.4887 - output_2_loss: 1.5236 - val_loss: 0.7737 - val_output_1_loss: 0.4640 - val_output_2_loss: 3.5607\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5748 - output_1_loss: 0.4753 - output_2_loss: 1.4706 - val_loss: 0.7034 - val_output_1_loss: 0.4436 - val_output_2_loss: 3.0416\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5611 - output_1_loss: 0.4648 - output_2_loss: 1.4278 - val_loss: 0.6535 - val_output_1_loss: 0.4316 - val_output_2_loss: 2.6501\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5505 - output_1_loss: 0.4571 - output_2_loss: 1.3913 - val_loss: 0.6161 - val_output_1_loss: 0.4233 - val_output_2_loss: 2.3516\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_val_A, X_val_B), (y_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6325ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 724us/step - loss: 0.5451 - output_1_loss: 0.4518 - output_2_loss: 1.3849\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate([X_test_A, X_test_B],[y_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81834b",
   "metadata": {},
   "source": [
    "# Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b358376",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e431a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.4622 - val_loss: 0.7607\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6810 - val_loss: 0.6462\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.6054 - val_loss: 0.5799\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.5572 - val_loss: 0.5208\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5232 - val_loss: 0.4855\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4956 - val_loss: 0.4577\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4748 - val_loss: 0.4381\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4580 - val_loss: 0.4246\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4142\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.4089\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4273 - val_loss: 0.4067\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4208 - val_loss: 0.4055\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4156 - val_loss: 0.4046\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4112 - val_loss: 0.4015\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.4074 - val_loss: 0.4009\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.3950\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.3969\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.3986 - val_loss: 0.3970\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.3958 - val_loss: 0.3892\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.3939 - val_loss: 0.4058\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3916 - val_loss: 0.4007\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.4013\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 952us/step - loss: 0.3878 - val_loss: 0.3796\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3859 - val_loss: 0.3825\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3842 - val_loss: 0.3878\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3896\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3811 - val_loss: 0.3744\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3788\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3695\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.3740\n",
      "162/162 [==============================] - 0s 665us/step - loss: 0.3732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_11/kernel:0' shape=(8, 30) dtype=float32, numpy=\n",
       " array([[-0.12087043,  0.28481257,  0.31336507, -0.37000388, -0.36882052,\n",
       "         -0.11483479, -0.27037796, -0.14777307,  0.30924073,  0.4241558 ,\n",
       "         -0.37212482,  0.13658507,  0.22353883, -0.31132403, -0.38484865,\n",
       "         -0.27470568, -0.04676881, -0.13332978,  0.1833537 , -0.18632115,\n",
       "          0.3080944 , -0.05635306, -0.06391677,  0.38140365, -0.15410374,\n",
       "         -0.4486882 ,  0.28715903,  0.15308477,  0.19132423, -0.05248149],\n",
       "        [ 0.19933884,  0.2886085 , -0.01164274,  0.00294578, -0.12389822,\n",
       "         -0.34602547, -0.06061186,  0.08724023, -0.09141105,  0.27745998,\n",
       "         -0.30206764,  0.09970113,  0.23616503, -0.19468474, -0.17102586,\n",
       "         -0.1511357 , -0.2374795 , -0.25580958,  0.11415473,  0.12594832,\n",
       "         -0.046075  ,  0.04251806,  0.23041263,  0.1990844 ,  0.04652935,\n",
       "         -0.17252716,  0.21871778,  0.26639676,  0.01577725, -0.3525061 ],\n",
       "        [-0.43448058, -0.15865672, -0.10589498, -0.11564399, -0.36260024,\n",
       "         -0.09347548,  0.06029707, -0.1020103 ,  0.09028796,  0.3527376 ,\n",
       "         -0.22889774, -0.18663338,  0.22726811, -0.09640143,  0.14687774,\n",
       "          0.03559728,  0.1889494 , -0.3871114 ,  0.30830732, -0.10002129,\n",
       "          0.20518951,  0.29320353,  0.31525046,  0.02329158,  0.22254962,\n",
       "          0.12723726,  0.23780213,  0.11523227, -0.14913246,  0.42055163],\n",
       "        [ 0.02060502, -0.2299836 ,  0.00226827, -0.08809011, -0.26358843,\n",
       "          0.11312993, -0.4106042 , -0.32726917, -0.3624173 ,  0.17843004,\n",
       "         -0.39010012,  0.11874068, -0.16221544, -0.20484991,  0.30518538,\n",
       "         -0.1288401 , -0.01236848,  0.31086886, -0.20460805,  0.325191  ,\n",
       "          0.08580745,  0.26892972, -0.05753679,  0.00553764,  0.40938044,\n",
       "         -0.24107817, -0.41144398, -0.12671217,  0.12145012, -0.09501788],\n",
       "        [-0.2800079 ,  0.02928982,  0.15183024, -0.2583965 ,  0.35949385,\n",
       "         -0.08627702, -0.06216587,  0.09233575,  0.29413387,  0.11886318,\n",
       "         -0.39212242, -0.09522593, -0.3625003 ,  0.1610707 , -0.34548002,\n",
       "         -0.05146153, -0.01508002,  0.019329  , -0.26365888,  0.20321131,\n",
       "         -0.41324362, -0.27232692, -0.2634944 ,  0.01005949,  0.15181625,\n",
       "          0.24552575, -0.23332559, -0.14321855,  0.15148117, -0.3666713 ],\n",
       "        [ 0.04330254, -0.47914433, -0.4979283 , -0.21998598,  0.27019298,\n",
       "         -0.22778732,  0.35919687,  0.07818499, -0.3279142 ,  0.15450437,\n",
       "         -0.03689595, -0.1306593 , -0.23348293, -0.0299725 , -0.21656488,\n",
       "         -0.26681253, -0.35204032, -0.0278165 ,  0.2972385 , -0.47138312,\n",
       "          0.14812492,  0.09226946,  0.20072572, -0.5244983 ,  0.15951927,\n",
       "         -0.3488307 ,  0.02161625, -0.40952393, -0.26688507,  0.03605739],\n",
       "        [-0.04551793,  0.12873264, -0.15124744,  0.04231273, -0.19949889,\n",
       "          0.23887248, -0.3252137 ,  0.01807467, -0.04518924, -0.3212693 ,\n",
       "         -0.21870925, -0.17721114, -0.35444382, -0.21284698,  0.31114948,\n",
       "         -0.3748179 , -0.3004644 , -0.115848  ,  0.10446073, -0.4495753 ,\n",
       "          0.12284831,  0.2167918 , -0.13073465, -0.42036968,  0.275346  ,\n",
       "          0.12092087, -0.19225764, -0.3426532 , -0.4958281 , -0.20955247],\n",
       "        [-0.3122665 ,  0.19066913, -0.23778465, -0.03315968,  0.40506375,\n",
       "          0.0185508 ,  0.257133  , -0.20143974, -0.05187299,  0.20541374,\n",
       "         -0.21153776,  0.2977372 , -0.18966244,  0.33064753,  0.08560559,\n",
       "         -0.23380667,  0.29161835, -0.3284525 , -0.03375057, -0.4296224 ,\n",
       "          0.27657783, -0.3763032 , -0.1128237 , -0.24204068,  0.09369932,\n",
       "          0.03638365,  0.26055104,  0.28062966, -0.4033914 , -0.13699713]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_11/bias:0' shape=(30,) dtype=float32, numpy=\n",
       " array([ 0.08216051,  0.07579377,  0.2724391 ,  0.04158726,  0.08006851,\n",
       "         0.00720474, -0.01178341,  0.05606494,  0.04381099,  0.08718681,\n",
       "        -0.00406418,  0.03956325,  0.00117197,  0.01299415,  0.08605834,\n",
       "         0.03723787,  0.00494092, -0.05026942,  0.01455069,  0.10623363,\n",
       "         0.01704203,  0.01859314, -0.03855781,  0.16406676, -0.00035784,\n",
       "         0.03984611, -0.0304654 ,  0.02585069,  0.33888572,  0.08491809],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_12/kernel:0' shape=(30, 30) dtype=float32, numpy=\n",
       " array([[-0.01296932, -0.26784766,  0.22115457,  0.21143644,  0.12750389,\n",
       "         -0.0205183 , -0.0207838 ,  0.09731579,  0.22715218, -0.10170125,\n",
       "          0.08430084, -0.14954524, -0.2017407 ,  0.00147578, -0.00271365,\n",
       "         -0.16830929,  0.2078063 , -0.07029205,  0.18329464, -0.06139774,\n",
       "         -0.17435387,  0.10983277,  0.1400394 ,  0.22226459,  0.04633763,\n",
       "          0.015864  ,  0.2355684 ,  0.07496958,  0.04994934, -0.08814732],\n",
       "        [ 0.10913317,  0.0630382 , -0.01430709,  0.24080682, -0.29887915,\n",
       "         -0.11023811,  0.20475607,  0.10504059, -0.16786864, -0.31280923,\n",
       "         -0.14494596,  0.23239432,  0.20591737,  0.24785057, -0.28915304,\n",
       "          0.2357086 , -0.19683152,  0.10591129,  0.17692697, -0.14632162,\n",
       "          0.20519525, -0.09709667, -0.07565723, -0.01322528,  0.12960382,\n",
       "         -0.21717194, -0.31256756,  0.16147102,  0.13736789, -0.22496139],\n",
       "        [ 0.08614303,  0.09400656,  0.03986767,  0.04177888,  0.16870397,\n",
       "         -0.25668734, -0.14926298, -0.09737808, -0.06783434,  0.18461226,\n",
       "          0.01564247,  0.07699684,  0.36350408,  0.32931238,  0.29472807,\n",
       "         -0.33149502, -0.00963344, -0.04486368, -0.06145452, -0.2969777 ,\n",
       "         -0.04396605,  0.3530932 , -0.14038269,  0.28987953,  0.01544276,\n",
       "         -0.29773563,  0.03259021,  0.01300355,  0.2580691 , -0.20539226],\n",
       "        [-0.10482625, -0.28393725,  0.19392772,  0.06677006, -0.05392444,\n",
       "         -0.19289048, -0.08028021, -0.07245228,  0.19252229, -0.18378097,\n",
       "         -0.10503533,  0.06281434,  0.12912826,  0.00883961,  0.08042127,\n",
       "          0.04993265, -0.06536689, -0.09246666, -0.18511945, -0.11830901,\n",
       "         -0.00926086, -0.29190096, -0.29418314, -0.18320568,  0.20648333,\n",
       "         -0.08551018, -0.07043968,  0.26672313, -0.28024158,  0.27875745],\n",
       "        [ 0.09393275,  0.0828453 ,  0.01670741,  0.01659696, -0.00084046,\n",
       "         -0.1359534 ,  0.1155023 ,  0.15256394,  0.10175762,  0.12399197,\n",
       "          0.10954917, -0.06777962, -0.34690437, -0.21433434,  0.01338084,\n",
       "         -0.22178812, -0.06781115,  0.03195814, -0.2657831 ,  0.05023437,\n",
       "          0.30931917, -0.22245139,  0.19146533,  0.27989852,  0.2075312 ,\n",
       "         -0.3122049 , -0.2067935 ,  0.16075613,  0.13328971, -0.25837514],\n",
       "        [ 0.24038686, -0.03558012, -0.26153687, -0.15000404,  0.12829427,\n",
       "          0.04710295, -0.00870378,  0.01337018, -0.2765418 ,  0.21806729,\n",
       "         -0.15581764, -0.15778206, -0.04725831,  0.1501331 , -0.19217604,\n",
       "         -0.2774925 , -0.18546449,  0.10160424, -0.23414958,  0.28144792,\n",
       "         -0.03104208, -0.13408466,  0.10810328,  0.14998743, -0.01253069,\n",
       "         -0.29204315, -0.22375786,  0.16528201, -0.24261513,  0.10875422],\n",
       "        [ 0.23182435,  0.22671583, -0.00846178, -0.33680272, -0.1221761 ,\n",
       "          0.19459605,  0.14204134,  0.15834567, -0.26019266, -0.06604509,\n",
       "          0.05562065, -0.33173504, -0.05036145,  0.13375857,  0.07080439,\n",
       "         -0.19204377, -0.08503853, -0.14895873,  0.18514736, -0.06924864,\n",
       "          0.23222785, -0.17412037, -0.28749505, -0.19507788, -0.09958974,\n",
       "          0.03196047,  0.19717726,  0.01879502, -0.0257317 , -0.26484433],\n",
       "        [-0.32766747, -0.07095011, -0.01755582,  0.04701901,  0.03823874,\n",
       "         -0.31499687, -0.28309292,  0.23552929,  0.12499942,  0.26752296,\n",
       "         -0.2041222 , -0.15718365,  0.17107108, -0.2156218 ,  0.3141788 ,\n",
       "         -0.06819752, -0.3096736 , -0.27489984, -0.20682245,  0.15930507,\n",
       "          0.17301024, -0.30865797,  0.09579904, -0.07927804,  0.1315672 ,\n",
       "         -0.20456196, -0.3165921 , -0.14700358, -0.2849055 ,  0.2639334 ],\n",
       "        [-0.30481225, -0.03241762, -0.31207845, -0.14375956,  0.01641787,\n",
       "          0.12301084, -0.04963843,  0.26421833, -0.19781677, -0.22001563,\n",
       "         -0.16566429,  0.15994664,  0.1819646 , -0.08672373, -0.08178484,\n",
       "          0.14015578,  0.03150088, -0.07727117, -0.28525248, -0.04534873,\n",
       "          0.23005024,  0.14145154,  0.03211062,  0.14375584,  0.22093599,\n",
       "         -0.20181018,  0.00998902, -0.19149885, -0.07787572,  0.20213668],\n",
       "        [ 0.1546541 ,  0.1976088 ,  0.13326837, -0.15612775,  0.19664134,\n",
       "         -0.0050121 ,  0.16683486,  0.2839863 ,  0.23077427,  0.26504487,\n",
       "          0.1549715 , -0.17678566,  0.23151438, -0.05136447, -0.14737538,\n",
       "          0.09493014,  0.08240433,  0.11508955, -0.11195787,  0.31993052,\n",
       "         -0.08705863, -0.16419928,  0.29969403, -0.18913795, -0.2789867 ,\n",
       "         -0.01380516, -0.16768377,  0.08369393, -0.14435609, -0.25743502],\n",
       "        [ 0.1076571 ,  0.12912346, -0.07443221, -0.13038269, -0.01168351,\n",
       "         -0.18310508,  0.26154056,  0.21822065,  0.14278516,  0.04826127,\n",
       "         -0.14715664, -0.24352323,  0.00153174,  0.30800655,  0.19104533,\n",
       "         -0.06556463, -0.12342398,  0.07188978,  0.19606292, -0.02369867,\n",
       "          0.13647719,  0.08265892, -0.18717448,  0.08701938, -0.09944422,\n",
       "          0.07448912,  0.18246344, -0.0290733 ,  0.1204036 , -0.08530312],\n",
       "        [-0.0023649 , -0.07427371,  0.06475581,  0.32598045,  0.04243097,\n",
       "         -0.10975216,  0.09385604, -0.2747057 , -0.2975801 , -0.23366007,\n",
       "          0.12106226, -0.2688832 ,  0.09964012, -0.01098916, -0.09557954,\n",
       "          0.05995015, -0.0060895 ,  0.3038166 , -0.0697751 , -0.03312973,\n",
       "          0.12589239,  0.0423332 ,  0.16174537,  0.17233649, -0.2285643 ,\n",
       "          0.16119204,  0.14678651, -0.04692617,  0.02336532, -0.15693279],\n",
       "        [ 0.24134237, -0.23702206,  0.11110465, -0.10550386, -0.17531522,\n",
       "         -0.16545096,  0.08853286, -0.06465036,  0.08849844,  0.11278929,\n",
       "          0.37955096,  0.01015172, -0.23568961, -0.04992131,  0.31454504,\n",
       "         -0.23656984, -0.06279638,  0.00344676, -0.045865  , -0.00540574,\n",
       "         -0.1612517 ,  0.11511176, -0.03422181, -0.25830516, -0.3132625 ,\n",
       "         -0.2695403 , -0.06231106, -0.18415864,  0.0777195 , -0.12656054],\n",
       "        [ 0.00361207, -0.02993083, -0.26398686, -0.07866614,  0.12575617,\n",
       "         -0.14290005, -0.12528165,  0.01584105, -0.17263295,  0.26205444,\n",
       "          0.17309892,  0.24887621, -0.3072017 , -0.22894743,  0.09121946,\n",
       "          0.00546368,  0.02717285, -0.3055521 ,  0.2777769 , -0.11580511,\n",
       "         -0.12910321, -0.17591718,  0.1223228 , -0.20209298, -0.25636426,\n",
       "          0.00759726,  0.2803312 , -0.01703973, -0.29252034, -0.04201189],\n",
       "        [-0.30811822,  0.27126053,  0.31822032, -0.14337337, -0.17855743,\n",
       "         -0.05059829, -0.0881517 , -0.18131867, -0.07389402, -0.1802967 ,\n",
       "          0.03499705, -0.23570739,  0.02076474, -0.29415584,  0.09282126,\n",
       "          0.04719755, -0.09257032,  0.2679802 , -0.04558533,  0.26076248,\n",
       "          0.23648307, -0.01400812,  0.29350019,  0.27081487,  0.16711387,\n",
       "         -0.27013627,  0.24614501, -0.01376282, -0.19281247, -0.04764227],\n",
       "        [-0.2304192 ,  0.12540878, -0.00732746,  0.2592928 , -0.00534705,\n",
       "          0.09315436, -0.22056739,  0.21966866, -0.00371935, -0.15562338,\n",
       "         -0.09316649, -0.21895425, -0.12878977,  0.1490965 ,  0.21208543,\n",
       "         -0.01809842,  0.06245074,  0.25705245, -0.12852591,  0.2332264 ,\n",
       "         -0.26064736,  0.33582908,  0.21340221, -0.13525012, -0.22079015,\n",
       "         -0.00294359,  0.14195868,  0.09451336, -0.2285997 , -0.18349884],\n",
       "        [ 0.2821097 , -0.16159137, -0.00442067,  0.14657769, -0.23254965,\n",
       "          0.07203544,  0.19613127, -0.21985656,  0.26904413,  0.03533572,\n",
       "         -0.27053308,  0.14365254, -0.00750201, -0.10175623, -0.2689513 ,\n",
       "          0.08025716, -0.20518629, -0.02622497,  0.19761248, -0.20898089,\n",
       "         -0.20050508,  0.24758707,  0.3169116 ,  0.12128113, -0.00450612,\n",
       "          0.17518836,  0.21496683,  0.20077491, -0.00401848, -0.14918128],\n",
       "        [ 0.20633484,  0.0793874 ,  0.29862502, -0.2589764 ,  0.00640005,\n",
       "          0.02359929,  0.02404256,  0.26537412, -0.1838375 , -0.1869957 ,\n",
       "          0.23675215, -0.08940604, -0.20688546,  0.04340877, -0.23780845,\n",
       "          0.18214814, -0.0275868 ,  0.21529877,  0.04171839, -0.2659714 ,\n",
       "          0.12391926, -0.00546313, -0.02714086,  0.2533946 , -0.17406738,\n",
       "          0.10546935,  0.00325541,  0.26042774,  0.28049612,  0.22813936],\n",
       "        [-0.04776648, -0.1399108 , -0.00528874, -0.3301303 , -0.13822909,\n",
       "         -0.19629589, -0.1294785 , -0.08160361, -0.12062151,  0.14565615,\n",
       "         -0.06796091, -0.12000373,  0.2465712 , -0.21632966,  0.04625623,\n",
       "         -0.31714204,  0.02549402,  0.21651347, -0.22795796, -0.22524096,\n",
       "         -0.29067966, -0.12024464,  0.11342351,  0.08489855, -0.09838989,\n",
       "          0.20765346, -0.23487665,  0.16625121, -0.0035112 ,  0.07291955],\n",
       "        [-0.3091602 ,  0.08720911,  0.18962945,  0.12731273,  0.1743991 ,\n",
       "          0.08492022,  0.14358254, -0.3076293 , -0.00535776, -0.10212729,\n",
       "          0.28587234,  0.33446923, -0.28773236,  0.16545215,  0.11391086,\n",
       "          0.0189841 ,  0.03810335,  0.26755664,  0.2074631 , -0.03610747,\n",
       "          0.06101982,  0.06407414,  0.02696774, -0.20450711, -0.21205361,\n",
       "         -0.23646095,  0.22403108,  0.1984914 ,  0.15980521, -0.18330963],\n",
       "        [-0.29956263,  0.27487487, -0.26494372,  0.16252428, -0.08827353,\n",
       "          0.21907707, -0.24184781, -0.2695029 , -0.02634858,  0.10206941,\n",
       "         -0.19297746, -0.02536906, -0.29378256,  0.16991705,  0.19087909,\n",
       "         -0.21351585,  0.04276549,  0.25447503, -0.2336524 , -0.06056318,\n",
       "         -0.20126885,  0.2434883 ,  0.01365361, -0.25280744,  0.02705731,\n",
       "          0.247834  ,  0.15499608,  0.15408836, -0.0415466 , -0.03402179],\n",
       "        [-0.07085612, -0.25220996, -0.23844281,  0.04866952,  0.24829133,\n",
       "          0.2438908 , -0.05126166,  0.32875258,  0.18104178,  0.0546516 ,\n",
       "          0.08660536,  0.16522597,  0.08268391,  0.20900503,  0.11077777,\n",
       "         -0.24335645, -0.18944459, -0.29570752,  0.12966876,  0.20613569,\n",
       "          0.29519728,  0.10177219,  0.1562287 , -0.13584667,  0.26282856,\n",
       "         -0.28224802, -0.09780516,  0.03574793, -0.04236439,  0.05148703],\n",
       "        [ 0.15860167,  0.18985888, -0.02744718, -0.259149  ,  0.28143445,\n",
       "         -0.06477783,  0.21437573, -0.280023  ,  0.21807824, -0.20756432,\n",
       "         -0.09233731, -0.09174753,  0.3330803 , -0.1113243 , -0.04629815,\n",
       "          0.30594742, -0.06603929, -0.21386917, -0.28154662, -0.14085625,\n",
       "          0.29058   ,  0.09574771, -0.3125469 , -0.30374607,  0.08834957,\n",
       "         -0.03252352, -0.18795125,  0.18149096,  0.001871  , -0.27882534],\n",
       "        [-0.15814199,  0.24181125, -0.1236944 ,  0.38224536,  0.17377117,\n",
       "          0.00822346, -0.0491477 ,  0.06486968,  0.10321258, -0.19561963,\n",
       "          0.33856273,  0.11356545,  0.12346704,  0.4028714 , -0.0484194 ,\n",
       "          0.24418728, -0.14863345, -0.13796371, -0.0902325 ,  0.1418398 ,\n",
       "         -0.27631313,  0.27004644,  0.1957487 , -0.23347126, -0.13885422,\n",
       "          0.0614218 ,  0.21227728,  0.11048697,  0.01476608, -0.04696079],\n",
       "        [-0.25003427,  0.26589522,  0.14823748,  0.05368128, -0.06459217,\n",
       "         -0.16390824, -0.05497513,  0.25036877,  0.07746069, -0.26945534,\n",
       "          0.08523503, -0.21124996,  0.16007909, -0.09284535, -0.27966997,\n",
       "         -0.20320918, -0.09707811, -0.02303867,  0.23993807,  0.0549395 ,\n",
       "         -0.12340993, -0.17718792, -0.28269362,  0.2832042 ,  0.25223666,\n",
       "         -0.01124416, -0.13983822, -0.16728894, -0.133111  , -0.22032325],\n",
       "        [ 0.11975   ,  0.19587055,  0.2183659 , -0.21214826, -0.17707762,\n",
       "          0.27858353, -0.0598483 ,  0.03256524,  0.18384047, -0.11000147,\n",
       "         -0.347425  , -0.10763956,  0.16616303,  0.2794169 ,  0.26112032,\n",
       "          0.01531237, -0.13040489, -0.00501468,  0.25385612,  0.30453417,\n",
       "         -0.05053797, -0.2690708 , -0.03226704,  0.15661582,  0.33443138,\n",
       "          0.12377644,  0.21504338, -0.22073784, -0.16197965, -0.23230292],\n",
       "        [-0.2994519 , -0.09080599, -0.2524886 , -0.32820475, -0.06238616,\n",
       "          0.06821345, -0.10474312, -0.18312143, -0.05792858,  0.0236147 ,\n",
       "         -0.07234763, -0.2629529 , -0.0560262 , -0.01731168, -0.22971816,\n",
       "         -0.24435154,  0.00090548,  0.14827046, -0.10498236,  0.24879795,\n",
       "          0.23097162,  0.01846373, -0.00883369, -0.21909018, -0.17493135,\n",
       "         -0.23382434,  0.05293291, -0.32486334,  0.1990101 , -0.0971283 ],\n",
       "        [ 0.19265074,  0.22133777,  0.24343789, -0.20467809,  0.16426258,\n",
       "          0.12823966, -0.00788213, -0.30027243, -0.29142407,  0.14545648,\n",
       "          0.28840342,  0.28952837,  0.17998964, -0.2295266 , -0.14765339,\n",
       "          0.08339112,  0.0344275 ,  0.10094109, -0.17880157,  0.10066962,\n",
       "         -0.05252633,  0.19362606, -0.15638052,  0.08060644, -0.0830873 ,\n",
       "         -0.02395832, -0.12303539,  0.05431539,  0.1453112 ,  0.19097117],\n",
       "        [-0.00849972,  0.05764288, -0.31601238,  0.34201658, -0.21739087,\n",
       "         -0.1026059 ,  0.30542642, -0.00543407,  0.00114755,  0.29690447,\n",
       "          0.31871384,  0.23669909,  0.39795715,  0.3312252 ,  0.21760038,\n",
       "         -0.133499  , -0.03602716,  0.09153114,  0.12882069,  0.29354292,\n",
       "         -0.05468546,  0.10934273, -0.17706873,  0.30545983, -0.11129802,\n",
       "         -0.00654878,  0.09236988, -0.05509233, -0.06623267, -0.15571125],\n",
       "        [ 0.10907031, -0.28387648,  0.1736676 , -0.14248616,  0.20810175,\n",
       "          0.20204565, -0.15579544,  0.19149913,  0.10338822,  0.00762579,\n",
       "          0.09613526,  0.22539592, -0.1525987 ,  0.19453827, -0.2029808 ,\n",
       "         -0.29875982,  0.08550321, -0.20145872,  0.20477055, -0.22054124,\n",
       "          0.12709686,  0.09418973, -0.13705944, -0.11751755, -0.19417207,\n",
       "          0.01428631,  0.2491363 ,  0.23711663,  0.2613601 , -0.01963762]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_12/bias:0' shape=(30,) dtype=float32, numpy=\n",
       " array([-1.11281030e-01, -1.72643185e-01,  2.16558613e-02,  1.06242813e-01,\n",
       "         1.27704114e-01,  1.91615301e-03,  7.91972056e-02,  7.19157457e-02,\n",
       "        -5.94811030e-02,  1.80006266e-01,  2.25485101e-01,  7.66417310e-02,\n",
       "         1.51783004e-01,  2.75160730e-01,  2.07155105e-02, -4.17850800e-02,\n",
       "        -6.88341539e-03,  4.18127291e-02,  5.67005202e-02, -1.97175834e-02,\n",
       "         2.99863610e-02,  1.78904444e-01,  5.75536601e-02,  3.25623490e-02,\n",
       "         2.69938111e-02, -1.63661316e-02, -2.38460824e-02,  1.20259605e-01,\n",
       "        -3.65959816e-02,  1.05025312e-04], dtype=float32)>,\n",
       " <tf.Variable 'dense_13/kernel:0' shape=(30, 1) dtype=float32, numpy=\n",
       " array([[-0.45639905],\n",
       "        [-0.40144786],\n",
       "        [-0.30385038],\n",
       "        [ 0.5461375 ],\n",
       "        [ 0.28284964],\n",
       "        [ 0.05931642],\n",
       "        [ 0.27357265],\n",
       "        [ 0.19143726],\n",
       "        [-0.2773036 ],\n",
       "        [ 0.34043533],\n",
       "        [ 0.5992276 ],\n",
       "        [ 0.3846778 ],\n",
       "        [ 0.50863147],\n",
       "        [ 0.6447582 ],\n",
       "        [ 0.12225749],\n",
       "        [-0.273247  ],\n",
       "        [-0.4296525 ],\n",
       "        [ 0.09172955],\n",
       "        [ 0.22730064],\n",
       "        [-0.10736996],\n",
       "        [-0.20452721],\n",
       "        [ 0.54885584],\n",
       "        [ 0.0731756 ],\n",
       "        [ 0.12063657],\n",
       "        [-0.32742092],\n",
       "        [-0.16689014],\n",
       "        [-0.0237324 ],\n",
       "        [ 0.32023355],\n",
       "        [-0.020926  ],\n",
       "        [ 0.00670518]], dtype=float32)>,\n",
       " <tf.Variable 'dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([0.5256007], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c54ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b407569",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e77e1101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x293db03dcd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4cc1f",
   "metadata": {},
   "source": [
    "# Callbacks during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc12b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6d5772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a535046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c7b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2130 - val_loss: 1.1679\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7856 - val_loss: 0.6840\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6924 - val_loss: 0.6272\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.6432 - val_loss: 0.5987\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.6068 - val_loss: 0.5549\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 961us/step - loss: 0.5737 - val_loss: 0.5300\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.5475 - val_loss: 0.5029\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.5242 - val_loss: 0.4806\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5043 - val_loss: 0.4638\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.4875 - val_loss: 0.4480\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.4392\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.4608 - val_loss: 0.4243\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4504 - val_loss: 0.4153\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4097\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4347 - val_loss: 0.4022\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.4288 - val_loss: 0.3967\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4094\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4195 - val_loss: 0.4009\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4149 - val_loss: 0.3878\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.4185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x293d8c54700>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb  = ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b242f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4086 - val_loss: 0.3860\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.4059 - val_loss: 0.4052\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.3928\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4004 - val_loss: 0.3975\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.3988 - val_loss: 0.3750\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3961 - val_loss: 0.4029\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.3772\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.3700\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.3701\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.3812\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3880 - val_loss: 0.3689\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.3940\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.3745\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.3672\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3640\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.3578\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3795 - val_loss: 0.3894\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3789 - val_loss: 0.3740\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3770 - val_loss: 0.3629\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3763 - val_loss: 0.4087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40860384702682495,\n",
       " 0.4058571457862854,\n",
       " 0.40334171056747437,\n",
       " 0.40038663148880005,\n",
       " 0.39876630902290344,\n",
       " 0.3960975408554077,\n",
       " 0.39479565620422363,\n",
       " 0.39277562499046326,\n",
       " 0.3909110724925995,\n",
       " 0.3891757130622864,\n",
       " 0.3880283236503601,\n",
       " 0.38614341616630554,\n",
       " 0.384860098361969,\n",
       " 0.3836929500102997,\n",
       " 0.3821837604045868,\n",
       " 0.38092494010925293,\n",
       " 0.3795040547847748,\n",
       " 0.3788672089576721,\n",
       " 0.376993864774704,\n",
       " 0.37634947896003723]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping_cb] )\n",
    "history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190264f7",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ecfe884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b41bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "015ecae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2023_04_27-09_45_23'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b5e7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc574377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18c1a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eef9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.0740 - val_loss: 1.9296\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.8635 - val_loss: 0.7333\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.7315 - val_loss: 0.7230\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6672 - val_loss: 0.6655\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6204 - val_loss: 0.6131\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5818 - val_loss: 0.5919\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5508 - val_loss: 0.5675\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5245 - val_loss: 0.5039\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5014 - val_loss: 0.4797\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4820 - val_loss: 0.4593\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4663 - val_loss: 0.4312\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4195\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4412 - val_loss: 0.4098\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4317 - val_loss: 0.4049\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4025\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.3974\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4119 - val_loss: 0.4012\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4015\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4027 - val_loss: 0.3913\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4160\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4165\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3935 - val_loss: 0.4206\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3910 - val_loss: 0.3827\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3886 - val_loss: 0.3935\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3865 - val_loss: 0.4006\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.4099\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3831 - val_loss: 0.3802\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3814 - val_loss: 0.3995\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.3934\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3784 - val_loss: 0.4069\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras.model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                   callbacks=[tensorboard_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c9bae",
   "metadata": {},
   "source": [
    "# Fine-Tuning NN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc9c0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa4efcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f88f86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8d90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_21864\\2375457609.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  ker_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 4.8865 - val_loss: 7.7963\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 4.6582 - val_loss: 7.1463\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 946us/step - loss: 4.4252 - val_loss: 6.5346\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 4.1938 - val_loss: 5.9657\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 3.9678 - val_loss: 5.4428\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 3.7506 - val_loss: 4.9624\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 3.5434 - val_loss: 4.5246\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 3.3462 - val_loss: 4.1305\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 957us/step - loss: 3.1586 - val_loss: 3.7721\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 2.9799 - val_loss: 3.4464\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 934us/step - loss: 2.8096 - val_loss: 3.1547\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 943us/step - loss: 2.6474 - val_loss: 2.8875\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 923us/step - loss: 2.4920 - val_loss: 2.6460\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 945us/step - loss: 2.3423 - val_loss: 2.4264\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 930us/step - loss: 2.1985 - val_loss: 2.2274\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 931us/step - loss: 2.0616 - val_loss: 2.0476\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 938us/step - loss: 1.9318 - val_loss: 1.8853\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 935us/step - loss: 1.8092 - val_loss: 1.7390\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 917us/step - loss: 1.6939 - val_loss: 1.6069\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 1.5863 - val_loss: 1.4885\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 945us/step - loss: 1.4870 - val_loss: 1.3831\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 959us/step - loss: 1.3961 - val_loss: 1.2899\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 1.3136 - val_loss: 1.2078\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 939us/step - loss: 1.2388 - val_loss: 1.1353\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 1.1713 - val_loss: 1.0715\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 1.1105 - val_loss: 1.0150\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 1.0559 - val_loss: 0.9643\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 1.0070 - val_loss: 0.9190\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.9633 - val_loss: 0.8786\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.9241 - val_loss: 0.8426\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.8890 - val_loss: 0.8104\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.8575 - val_loss: 0.7817\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8292 - val_loss: 0.7560\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.8037 - val_loss: 0.7329\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 0.7806 - val_loss: 0.7120\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.7597 - val_loss: 0.6931\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.7408 - val_loss: 0.6759\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.7236 - val_loss: 0.6604\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.7081 - val_loss: 0.6465\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.6941 - val_loss: 0.6339\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.6815 - val_loss: 0.6226\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.6702 - val_loss: 0.6125\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.6601 - val_loss: 0.6035\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.6510 - val_loss: 0.5954\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.6429 - val_loss: 0.5882\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.6357 - val_loss: 0.5818\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.6293 - val_loss: 0.5760\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.6235 - val_loss: 0.5709\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.6183 - val_loss: 0.5663\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6137 - val_loss: 0.5622\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.6095 - val_loss: 0.5585\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.6057 - val_loss: 0.5552\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6023 - val_loss: 0.5522\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.5992 - val_loss: 0.5494\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.5964 - val_loss: 0.5469\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.5937 - val_loss: 0.5446\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.5913 - val_loss: 0.5425\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.5891 - val_loss: 0.5405\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.5870 - val_loss: 0.5386\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.5850 - val_loss: 0.5369\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.5832 - val_loss: 0.5352\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.5815 - val_loss: 0.5337\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.5798 - val_loss: 0.5322\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 0.5782 - val_loss: 0.5307\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5767 - val_loss: 0.5294\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5280\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5738 - val_loss: 0.5268\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 0.5255\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 946us/step - loss: 0.5711 - val_loss: 0.5243\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5698 - val_loss: 0.5232\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5685 - val_loss: 0.5220\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.5673 - val_loss: 0.5209\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.5661 - val_loss: 0.5198\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.5650 - val_loss: 0.5188\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.5638 - val_loss: 0.5177\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.5627 - val_loss: 0.5167\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.5616 - val_loss: 0.5157\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5605 - val_loss: 0.5147\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.5594 - val_loss: 0.5138\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 943us/step - loss: 0.5584 - val_loss: 0.5128\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.5573 - val_loss: 0.5119\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.5563 - val_loss: 0.5109\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.5553 - val_loss: 0.5100\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 953us/step - loss: 0.5543 - val_loss: 0.5091\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5533 - val_loss: 0.5082\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5523 - val_loss: 0.5073\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5514 - val_loss: 0.5064\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5504 - val_loss: 0.5056\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 0.5047\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.5485 - val_loss: 0.5039\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.5030\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5467 - val_loss: 0.5022\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5458 - val_loss: 0.5014\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5449 - val_loss: 0.5006\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5440 - val_loss: 0.4998\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5431 - val_loss: 0.4990\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.4982\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.5414 - val_loss: 0.4975\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5406 - val_loss: 0.4967\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5398 - val_loss: 0.4959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'build_fn': <function __main__.build_model(n_hidden=1, n_neurons=30, learning_rate=0.003, input_shape=[8])>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ker_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "ker_reg.fit(X_train, y_train, epochs=100,\n",
    "           validation_data=(X_val, y_val),\n",
    "           callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "ker_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95533173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e873824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3974 - val_loss: 0.6864\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5961 - val_loss: 0.4964\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 0.5359 - val_loss: 0.4751\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.5165 - val_loss: 0.4620\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5007 - val_loss: 0.4504\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4899 - val_loss: 0.4454\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4846 - val_loss: 0.4418\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4805 - val_loss: 0.4421\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 0.4780 - val_loss: 0.4391\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.4341\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.4750 - val_loss: 0.4393\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4741 - val_loss: 0.4362\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4711 - val_loss: 0.4328\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4340\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4318\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4715 - val_loss: 0.4320\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.4706 - val_loss: 0.4354\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.4320\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4697 - val_loss: 0.4321\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4710 - val_loss: 0.4316\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4710 - val_loss: 0.4337\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4321\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4703 - val_loss: 0.4376\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4352\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.4337\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4328\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4330\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4316\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4701 - val_loss: 0.4324\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4701 - val_loss: 0.4323\n",
      "121/121 [==============================] - 0s 775us/step - loss: 0.4774\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   8.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.8556 - val_loss: 1.0510\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7021 - val_loss: 0.5239\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5460 - val_loss: 0.4919\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.4719\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5039 - val_loss: 0.4586\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4927 - val_loss: 0.4496\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4853 - val_loss: 0.4445\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4798 - val_loss: 0.4399\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4758 - val_loss: 0.4378\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4738 - val_loss: 0.4349\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4724 - val_loss: 0.4345\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4340\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4701 - val_loss: 0.4327\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4703 - val_loss: 0.4330\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.4321\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4689 - val_loss: 0.4316\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4672 - val_loss: 0.4325\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.4315\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4672 - val_loss: 0.4319\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 0.4321\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4319\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4684 - val_loss: 0.4321\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4679 - val_loss: 0.4323\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4677 - val_loss: 0.4320\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4317\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4315\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4325\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4309\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4665 - val_loss: 0.4332\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4319\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4315\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4684 - val_loss: 0.4314\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4668 - val_loss: 0.4333\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4315\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4315\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4315\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4323\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4314\n",
      "121/121 [==============================] - 0s 746us/step - loss: 0.4779\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  11.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7016 - val_loss: 1.1258\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7611 - val_loss: 0.5782\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6042 - val_loss: 0.5345\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - val_loss: 0.5042\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5413 - val_loss: 0.4806\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5207 - val_loss: 0.4645\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.4536\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4976 - val_loss: 0.4462\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4911 - val_loss: 0.4429\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4851 - val_loss: 0.4385\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4845 - val_loss: 0.4373\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4830 - val_loss: 0.4394\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4776 - val_loss: 0.4349\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4820 - val_loss: 0.4345\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4804 - val_loss: 0.4332\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4323\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4328\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4344\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4780 - val_loss: 0.4323\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4319\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4779 - val_loss: 0.4320\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.4321\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 0.4329\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4743 - val_loss: 0.4329\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4766 - val_loss: 0.4322\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.4333\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.4324\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4763 - val_loss: 0.4371\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4745 - val_loss: 0.4328\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4788 - val_loss: 0.4326\n",
      "121/121 [==============================] - 0s 733us/step - loss: 0.4638\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   9.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.1172 - val_loss: 5.2085\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6418 - val_loss: 4.8003\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9211 - val_loss: 4.1601\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.0123 - val_loss: 3.3355\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1575 - val_loss: 2.5599\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5670 - val_loss: 2.0336\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2288 - val_loss: 1.6688\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0314 - val_loss: 1.4059\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8966 - val_loss: 1.2099\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8118 - val_loss: 1.0731\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7499 - val_loss: 0.9625\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7019 - val_loss: 0.8879\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6731 - val_loss: 0.8331\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6532 - val_loss: 0.7916\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6379 - val_loss: 0.7584\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6251 - val_loss: 0.7309\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.7084\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 0.6899\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5957 - val_loss: 0.6740\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 0.6597\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5810 - val_loss: 0.6471\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5746 - val_loss: 0.6359\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5689 - val_loss: 0.6255\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5636 - val_loss: 0.6163\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.6080\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5546 - val_loss: 0.6005\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.5938\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5471 - val_loss: 0.5876\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5437 - val_loss: 0.5819\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5406 - val_loss: 0.5768\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5378 - val_loss: 0.5720\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5679\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5327 - val_loss: 0.5638\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5601\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5284 - val_loss: 0.5568\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5264 - val_loss: 0.5537\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 0.5506\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 0.5480\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5455\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.5435\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5186 - val_loss: 0.5416\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5173 - val_loss: 0.5397\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5161 - val_loss: 0.5379\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5149 - val_loss: 0.5363\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5139 - val_loss: 0.5348\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 0.5335\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5119 - val_loss: 0.5321\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5110 - val_loss: 0.5310\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5101 - val_loss: 0.5298\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5093 - val_loss: 0.5287\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5085 - val_loss: 0.5277\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5268\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5259\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5062 - val_loss: 0.5250\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5055 - val_loss: 0.5243\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5048 - val_loss: 0.5234\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5041 - val_loss: 0.5228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5035 - val_loss: 0.5222\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5029 - val_loss: 0.5216\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5022 - val_loss: 0.5212\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5017 - val_loss: 0.5210\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5011 - val_loss: 0.5209\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5006 - val_loss: 0.5206\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5000 - val_loss: 0.5204\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4994 - val_loss: 0.5202\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4989 - val_loss: 0.5199\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4984 - val_loss: 0.5198\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4978 - val_loss: 0.5197\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4974 - val_loss: 0.5198\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4968 - val_loss: 0.5199\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4964 - val_loss: 0.5202\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4959 - val_loss: 0.5203\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4955 - val_loss: 0.5201\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4950 - val_loss: 0.5201\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4946 - val_loss: 0.5201\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4940 - val_loss: 0.5201\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4937 - val_loss: 0.5202\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4933 - val_loss: 0.5207\n",
      "121/121 [==============================] - 0s 742us/step - loss: 0.4997\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  22.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.1734 - val_loss: 5.6712\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6790 - val_loss: 5.5012\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9262 - val_loss: 5.1890\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9658 - val_loss: 4.7585\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0267 - val_loss: 4.3166\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3939 - val_loss: 3.9415\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0742 - val_loss: 3.6209\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9163 - val_loss: 3.3162\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8286 - val_loss: 3.0317\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7751 - val_loss: 2.7767\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7399 - val_loss: 2.5456\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7138 - val_loss: 2.3407\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6928 - val_loss: 2.1616\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6752 - val_loss: 2.0062\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6599 - val_loss: 1.8679\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6464 - val_loss: 1.7496\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6345 - val_loss: 1.6482\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6237 - val_loss: 1.5602\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 1.4827\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6049 - val_loss: 1.4174\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 1.3673\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5893 - val_loss: 1.3231\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 1.2826\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 1.2462\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5702 - val_loss: 1.2133\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5649 - val_loss: 1.1836\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 1.1570\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5554 - val_loss: 1.1322\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5512 - val_loss: 1.1111\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5475 - val_loss: 1.0905\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5439 - val_loss: 1.0720\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5406 - val_loss: 1.0557\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5376 - val_loss: 1.0409\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 1.0279\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5322 - val_loss: 1.0160\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 1.0047\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5276 - val_loss: 0.9951\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.9857\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5235 - val_loss: 0.9779\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.9712\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5200 - val_loss: 0.9651\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.9598\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5168 - val_loss: 0.9544\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5154 - val_loss: 0.9503\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5140 - val_loss: 0.9469\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5128 - val_loss: 0.9432\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5115 - val_loss: 0.9407\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5104 - val_loss: 0.9390\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5094 - val_loss: 0.9375\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5083 - val_loss: 0.9360\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.9345\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.9345\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.9341\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5045 - val_loss: 0.9344\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5037 - val_loss: 0.9349\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5028 - val_loss: 0.9356\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5019 - val_loss: 0.9359\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5009 - val_loss: 0.9374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4997 - val_loss: 0.9381\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4975 - val_loss: 0.9365\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4864 - val_loss: 0.9188\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4625 - val_loss: 0.9055\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4505 - val_loss: 0.9018\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4454 - val_loss: 0.9022\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4428 - val_loss: 0.9045\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4415 - val_loss: 0.9072\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.9097\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.9132\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4391 - val_loss: 0.9166\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.9190\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4378 - val_loss: 0.9223\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4372 - val_loss: 0.9267\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.9306\n",
      "121/121 [==============================] - 0s 625us/step - loss: 0.4583\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  20.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.1749 - val_loss: 5.3790\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6943 - val_loss: 5.1033\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9772 - val_loss: 4.5884\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0896 - val_loss: 3.9008\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2725 - val_loss: 3.0485\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7279 - val_loss: 2.4195\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4327 - val_loss: 1.9732\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2503 - val_loss: 1.6449\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1191 - val_loss: 1.4023\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0284 - val_loss: 1.2361\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9592 - val_loss: 1.1171\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9106 - val_loss: 1.0397\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8768 - val_loss: 0.9860\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8521 - val_loss: 0.9440\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8304 - val_loss: 0.9060\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8060 - val_loss: 0.8653\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7746 - val_loss: 0.8240\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7473 - val_loss: 0.7925\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7232 - val_loss: 0.7608\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6932 - val_loss: 0.7277\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6709 - val_loss: 0.7074\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6581 - val_loss: 0.6931\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6492 - val_loss: 0.6816\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6420 - val_loss: 0.6720\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6358 - val_loss: 0.6634\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6303 - val_loss: 0.6558\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6254 - val_loss: 0.6488\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6208 - val_loss: 0.6426\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6166 - val_loss: 0.6371\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6128 - val_loss: 0.6318\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6273\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6060 - val_loss: 0.6231\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6030 - val_loss: 0.6192\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6001 - val_loss: 0.6159\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6128\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5950 - val_loss: 0.6100\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5928 - val_loss: 0.6075\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.6053\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5887 - val_loss: 0.6033\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5868 - val_loss: 0.6016\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5850 - val_loss: 0.6002\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5834 - val_loss: 0.5989\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - val_loss: 0.5975\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5804 - val_loss: 0.5965\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 0.5954\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5777 - val_loss: 0.5945\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5764 - val_loss: 0.5936\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5753 - val_loss: 0.5930\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5740 - val_loss: 0.5926\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - val_loss: 0.5924\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5719 - val_loss: 0.5923\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - val_loss: 0.5923\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5921\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - val_loss: 0.5918\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5681 - val_loss: 0.5917\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5916\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5665 - val_loss: 0.5916\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5933\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5649 - val_loss: 0.5950\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.5964\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5635 - val_loss: 0.5980\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5997\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5622 - val_loss: 0.6009\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5615 - val_loss: 0.6020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5609 - val_loss: 0.6027\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - val_loss: 0.6041\n",
      "121/121 [==============================] - 0s 612us/step - loss: 0.5510\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  17.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0143 - val_loss: 6.2706\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0037 - val_loss: 6.2489\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9931 - val_loss: 6.2272\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9823 - val_loss: 6.2055\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9715 - val_loss: 6.1838\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9606 - val_loss: 6.1620\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9496 - val_loss: 6.1403\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9386 - val_loss: 6.1185\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9276 - val_loss: 6.0968\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9164 - val_loss: 6.0750\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9052 - val_loss: 6.0533\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8940 - val_loss: 6.0315\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8827 - val_loss: 6.0097\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8714 - val_loss: 5.9880\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8600 - val_loss: 5.9662\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8486 - val_loss: 5.9445\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8371 - val_loss: 5.9227\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8256 - val_loss: 5.9010\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8141 - val_loss: 5.8793\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8025 - val_loss: 5.8576\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7909 - val_loss: 5.8360\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7793 - val_loss: 5.8143\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7676 - val_loss: 5.7927\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7559 - val_loss: 5.7711\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7442 - val_loss: 5.7495\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7324 - val_loss: 5.7279\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7206 - val_loss: 5.7064\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7088 - val_loss: 5.6850\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6970 - val_loss: 5.6635\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6852 - val_loss: 5.6421\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6733 - val_loss: 5.6208\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6614 - val_loss: 5.5994\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6495 - val_loss: 5.5782\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6376 - val_loss: 5.5569\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6257 - val_loss: 5.5357\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6137 - val_loss: 5.5146\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6018 - val_loss: 5.4923\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5898 - val_loss: 5.4713\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5779 - val_loss: 5.4503\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5659 - val_loss: 5.4294\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5539 - val_loss: 5.4085\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5419 - val_loss: 5.3876\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5299 - val_loss: 5.3668\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5179 - val_loss: 5.3460\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5059 - val_loss: 5.3253\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4939 - val_loss: 5.3047\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4818 - val_loss: 5.2841\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4698 - val_loss: 5.2635\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4578 - val_loss: 5.2430\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4457 - val_loss: 5.2225\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4337 - val_loss: 5.2021\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4216 - val_loss: 5.1818\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4096 - val_loss: 5.1615\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3976 - val_loss: 5.1412\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3855 - val_loss: 5.1211\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3735 - val_loss: 5.1010\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3614 - val_loss: 5.0809\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3494 - val_loss: 5.0609\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3374 - val_loss: 5.0409\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3253 - val_loss: 5.0210\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3133 - val_loss: 5.0012\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3012 - val_loss: 4.9814\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2892 - val_loss: 4.9617\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2772 - val_loss: 4.9421\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2652 - val_loss: 4.9225\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2532 - val_loss: 4.9029\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2412 - val_loss: 4.8835\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2292 - val_loss: 4.8641\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2172 - val_loss: 4.8447\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2053 - val_loss: 4.8254\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1933 - val_loss: 4.8062\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1813 - val_loss: 4.7870\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1694 - val_loss: 4.7679\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1575 - val_loss: 4.7489\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1455 - val_loss: 4.7299\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1336 - val_loss: 4.7110\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1217 - val_loss: 4.6921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1098 - val_loss: 4.6733\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0979 - val_loss: 4.6546\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0861 - val_loss: 4.6359\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0742 - val_loss: 4.6173\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0624 - val_loss: 4.5988\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0505 - val_loss: 4.5803\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 4.0387 - val_loss: 4.5619\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 4.0269 - val_loss: 4.5435\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 4.0151 - val_loss: 4.5252\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0034 - val_loss: 4.5070\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 3.9916 - val_loss: 4.4889\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 3.9799 - val_loss: 4.4708\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 3.9682 - val_loss: 4.4528\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 3.9565 - val_loss: 4.4349\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 3.9448 - val_loss: 4.4170\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 3.9331 - val_loss: 4.3992\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 3.9215 - val_loss: 4.3815\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 3.9098 - val_loss: 4.3638\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 3.8982 - val_loss: 4.3462\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 3.8866 - val_loss: 4.3287\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 3.8751 - val_loss: 4.3113\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 3.8635 - val_loss: 4.2939\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 3.8520 - val_loss: 4.2766\n",
      "121/121 [==============================] - 0s 621us/step - loss: 3.9996\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  26.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1334 - val_loss: 6.4294\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 5.1230 - val_loss: 6.4173\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 5.1125 - val_loss: 6.4052\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 5.1020 - val_loss: 6.3929\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 5.0914 - val_loss: 6.3805\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0807 - val_loss: 6.3680\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 5.0699 - val_loss: 6.3554\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 5.0591 - val_loss: 6.3427\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 5.0483 - val_loss: 6.3299\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 5.0374 - val_loss: 6.3170\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0264 - val_loss: 6.3040\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 5.0154 - val_loss: 6.2910\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 5.0043 - val_loss: 6.2779\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 4.9932 - val_loss: 6.2646\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 4.9821 - val_loss: 6.2513\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 4.9709 - val_loss: 6.2380\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 4.9596 - val_loss: 6.2245\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 4.9484 - val_loss: 6.2110\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 4.9371 - val_loss: 6.1975\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 4.9257 - val_loss: 6.1839\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 4.9144 - val_loss: 6.1702\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 4.9030 - val_loss: 6.1565\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 4.8916 - val_loss: 6.1428\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 4.8801 - val_loss: 6.1290\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 4.8687 - val_loss: 6.1151\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 4.8572 - val_loss: 6.1012\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 4.8457 - val_loss: 6.0873\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 4.8341 - val_loss: 6.0733\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8226 - val_loss: 6.0592\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 4.8110 - val_loss: 6.0452\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 4.7994 - val_loss: 6.0311\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 4.7878 - val_loss: 6.0169\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 4.7762 - val_loss: 6.0027\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 4.7646 - val_loss: 5.9885\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7530 - val_loss: 5.9743\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7413 - val_loss: 5.9600\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7297 - val_loss: 5.9457\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7180 - val_loss: 5.9314\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7063 - val_loss: 5.9170\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6947 - val_loss: 5.9027\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6830 - val_loss: 5.8883\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 4.6713 - val_loss: 5.8739\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6597 - val_loss: 5.8595\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 4.6480 - val_loss: 5.8450\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6363 - val_loss: 5.8306\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6247 - val_loss: 5.8161\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6130 - val_loss: 5.8016\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6013 - val_loss: 5.7872\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5897 - val_loss: 5.7727\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5780 - val_loss: 5.7582\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5664 - val_loss: 5.7437\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5548 - val_loss: 5.7291\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5432 - val_loss: 5.7146\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5316 - val_loss: 5.7001\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5200 - val_loss: 5.6856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5084 - val_loss: 5.6711\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4968 - val_loss: 5.6566\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4853 - val_loss: 5.6421\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4737 - val_loss: 5.6276\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4622 - val_loss: 5.6131\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4507 - val_loss: 5.5986\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4392 - val_loss: 5.5842\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4277 - val_loss: 5.5697\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4163 - val_loss: 5.5552\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4048 - val_loss: 5.5408\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3934 - val_loss: 5.5263\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3820 - val_loss: 5.5119\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3706 - val_loss: 5.4974\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3592 - val_loss: 5.4830\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3478 - val_loss: 5.4686\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 4.3365 - val_loss: 5.4543\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3252 - val_loss: 5.4399\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 4.3139 - val_loss: 5.4255\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3026 - val_loss: 5.4112\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2913 - val_loss: 5.3968\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2800 - val_loss: 5.3825\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2688 - val_loss: 5.3682\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2575 - val_loss: 5.3539\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 4.2463 - val_loss: 5.3396\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 4.2351 - val_loss: 5.3254\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2240 - val_loss: 5.3111\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2128 - val_loss: 5.2969\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2017 - val_loss: 5.2827\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1906 - val_loss: 5.2685\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1795 - val_loss: 5.2544\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1684 - val_loss: 5.2402\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1574 - val_loss: 5.2261\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1464 - val_loss: 5.2120\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1354 - val_loss: 5.1979\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1244 - val_loss: 5.1838\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1134 - val_loss: 5.1697\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1025 - val_loss: 5.1557\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0916 - val_loss: 5.1417\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0807 - val_loss: 5.1276\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0698 - val_loss: 5.1137\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0589 - val_loss: 5.0997\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0481 - val_loss: 5.0857\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0373 - val_loss: 5.0717\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0265 - val_loss: 5.0578\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0157 - val_loss: 5.0439\n",
      "121/121 [==============================] - 0s 621us/step - loss: 3.9648\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  24.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0464 - val_loss: 5.9400\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0341 - val_loss: 5.9180\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0218 - val_loss: 5.8961\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0095 - val_loss: 5.8742\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9971 - val_loss: 5.8523\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9847 - val_loss: 5.8304\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9722 - val_loss: 5.8085\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9598 - val_loss: 5.7867\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9473 - val_loss: 5.7650\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9348 - val_loss: 5.7433\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9223 - val_loss: 5.7216\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9098 - val_loss: 5.7000\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8973 - val_loss: 5.6785\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 4.8848 - val_loss: 5.6570\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8723 - val_loss: 5.6356\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8598 - val_loss: 5.6142\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8473 - val_loss: 5.5929\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8348 - val_loss: 5.5717\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8223 - val_loss: 5.5505\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8098 - val_loss: 5.5293\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7973 - val_loss: 5.5083\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7848 - val_loss: 5.4873\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7724 - val_loss: 5.4664\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7599 - val_loss: 5.4456\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 4.7475 - val_loss: 5.4249\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 4.7350 - val_loss: 5.4043\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7226 - val_loss: 5.3837\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7102 - val_loss: 5.3632\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6978 - val_loss: 5.3427\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6855 - val_loss: 5.3224\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6731 - val_loss: 5.3021\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6608 - val_loss: 5.2819\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6485 - val_loss: 5.2618\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6362 - val_loss: 5.2418\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6239 - val_loss: 5.2218\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6117 - val_loss: 5.2019\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5995 - val_loss: 5.1821\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5873 - val_loss: 5.1624\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5751 - val_loss: 5.1428\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5630 - val_loss: 5.1233\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5508 - val_loss: 5.1038\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5387 - val_loss: 5.0844\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5267 - val_loss: 5.0652\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5146 - val_loss: 5.0459\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5026 - val_loss: 5.0268\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4906 - val_loss: 5.0078\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4786 - val_loss: 4.9888\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4667 - val_loss: 4.9700\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 4.4547 - val_loss: 4.9512\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 4.4428 - val_loss: 4.9325\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 4.4310 - val_loss: 4.9139\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4191 - val_loss: 4.8954\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 4.4073 - val_loss: 4.8769\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3955 - val_loss: 4.8586\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3838 - val_loss: 4.8403\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3720 - val_loss: 4.8221\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3603 - val_loss: 4.8040\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3486 - val_loss: 4.7860\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3370 - val_loss: 4.7680\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3254 - val_loss: 4.7502\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 4.3138 - val_loss: 4.7324\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3022 - val_loss: 4.7148\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2907 - val_loss: 4.6972\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2792 - val_loss: 4.6797\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2677 - val_loss: 4.6622\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2563 - val_loss: 4.6449\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2448 - val_loss: 4.6276\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2335 - val_loss: 4.6105\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2221 - val_loss: 4.5934\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2108 - val_loss: 4.5763\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1995 - val_loss: 4.5594\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1882 - val_loss: 4.5425\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1769 - val_loss: 4.5258\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1657 - val_loss: 4.5091\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1545 - val_loss: 4.4924\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1433 - val_loss: 4.4759\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1322 - val_loss: 4.4594\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1211 - val_loss: 4.4431\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1100 - val_loss: 4.4268\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0990 - val_loss: 4.4106\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0880 - val_loss: 4.3944\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0770 - val_loss: 4.3783\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0660 - val_loss: 4.3623\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0550 - val_loss: 4.3464\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0441 - val_loss: 4.3305\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0332 - val_loss: 4.3148\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0224 - val_loss: 4.2991\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0115 - val_loss: 4.2835\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0008 - val_loss: 4.2680\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9900 - val_loss: 4.2525\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9792 - val_loss: 4.2371\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9685 - val_loss: 4.2218\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9579 - val_loss: 4.2066\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9472 - val_loss: 4.1914\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9366 - val_loss: 4.1764\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9260 - val_loss: 4.1613\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9154 - val_loss: 4.1464\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9049 - val_loss: 4.1315\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8944 - val_loss: 4.1167\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8839 - val_loss: 4.1020\n",
      "121/121 [==============================] - 0s 637us/step - loss: 3.7730\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  25.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.1379 - val_loss: 5.7408\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0101 - val_loss: 5.6814\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8577 - val_loss: 5.6043\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6794 - val_loss: 5.5057\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4749 - val_loss: 5.3814\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2447 - val_loss: 5.2362\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9908 - val_loss: 5.0602\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7178 - val_loss: 4.8538\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4319 - val_loss: 4.6135\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1405 - val_loss: 4.3541\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8520 - val_loss: 4.0653\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5732 - val_loss: 3.7430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3095 - val_loss: 3.4153\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0636 - val_loss: 3.0899\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8460 - val_loss: 2.7870\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6639 - val_loss: 2.5247\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5176 - val_loss: 2.2966\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4041 - val_loss: 2.1102\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3165 - val_loss: 1.9634\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2472 - val_loss: 1.8438\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1876 - val_loss: 1.7331\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1337 - val_loss: 1.6359\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0891 - val_loss: 1.5510\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0511 - val_loss: 1.4750\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0164 - val_loss: 1.4056\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9852 - val_loss: 1.3427\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9574 - val_loss: 1.2852\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9318 - val_loss: 1.2329\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9073 - val_loss: 1.1860\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8839 - val_loss: 1.1427\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8626 - val_loss: 1.1040\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8442 - val_loss: 1.0698\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8286 - val_loss: 1.0393\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8152 - val_loss: 1.0121\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8035 - val_loss: 0.9876\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7933 - val_loss: 0.9654\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7842 - val_loss: 0.9441\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7759 - val_loss: 0.9254\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7685 - val_loss: 0.9085\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7616 - val_loss: 0.8929\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7552 - val_loss: 0.8786\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7493 - val_loss: 0.8655\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7437 - val_loss: 0.8531\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7385 - val_loss: 0.8415\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7335 - val_loss: 0.8307\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7287 - val_loss: 0.8204\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7242 - val_loss: 0.8108\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7199 - val_loss: 0.8016\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7157 - val_loss: 0.7930\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7118 - val_loss: 0.7848\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7080 - val_loss: 0.7774\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7043 - val_loss: 0.7707\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7008 - val_loss: 0.7645\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6974 - val_loss: 0.7585\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6942 - val_loss: 0.7529\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6910 - val_loss: 0.7474\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6880 - val_loss: 0.7422\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6851 - val_loss: 0.7372\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6823 - val_loss: 0.7323\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6796 - val_loss: 0.7277\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6770 - val_loss: 0.7232\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6745 - val_loss: 0.7190\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6721 - val_loss: 0.7149\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6698 - val_loss: 0.7111\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6675 - val_loss: 0.7074\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6653 - val_loss: 0.7038\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6633 - val_loss: 0.7003\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6612 - val_loss: 0.6970\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6593 - val_loss: 0.6938\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6574 - val_loss: 0.6907\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6556 - val_loss: 0.6877\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6538 - val_loss: 0.6849\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6521 - val_loss: 0.6821\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6504 - val_loss: 0.6794\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6488 - val_loss: 0.6768\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6472 - val_loss: 0.6742\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6457 - val_loss: 0.6718\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6443 - val_loss: 0.6695\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6428 - val_loss: 0.6672\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6415 - val_loss: 0.6650\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6401 - val_loss: 0.6628\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6388 - val_loss: 0.6608\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6376 - val_loss: 0.6588\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6364 - val_loss: 0.6569\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6352 - val_loss: 0.6550\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6340 - val_loss: 0.6532\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6329 - val_loss: 0.6514\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 0.6497\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6308 - val_loss: 0.6481\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6298 - val_loss: 0.6465\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6288 - val_loss: 0.6449\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6278 - val_loss: 0.6434\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6420\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6259 - val_loss: 0.6405\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6250 - val_loss: 0.6392\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 0.6378\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6233 - val_loss: 0.6366\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6225 - val_loss: 0.6353\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6216 - val_loss: 0.6341\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6208 - val_loss: 0.6329\n",
      "121/121 [==============================] - 0s 625us/step - loss: 0.6255\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  26.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.3116 - val_loss: 5.5253\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1908 - val_loss: 5.4678\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0417 - val_loss: 5.3966\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8639 - val_loss: 5.3124\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6567 - val_loss: 5.2150\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4208 - val_loss: 5.1043\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1582 - val_loss: 4.9814\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8722 - val_loss: 4.8494\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5682 - val_loss: 4.7088\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2524 - val_loss: 4.5617\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9356 - val_loss: 4.4130\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6289 - val_loss: 4.2648\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3413 - val_loss: 4.1193\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0797 - val_loss: 3.9761\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8512 - val_loss: 3.8411\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6628 - val_loss: 3.7155\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5114 - val_loss: 3.5952\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3926 - val_loss: 3.4789\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3000 - val_loss: 3.3644\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2268 - val_loss: 3.2571\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1666 - val_loss: 3.1506\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1155 - val_loss: 3.0434\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0709 - val_loss: 2.9369\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0325 - val_loss: 2.8331\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9991 - val_loss: 2.7318\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9696 - val_loss: 2.6334\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9422 - val_loss: 2.5371\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9148 - val_loss: 2.4469\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8878 - val_loss: 2.3652\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8636 - val_loss: 2.2876\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8430 - val_loss: 2.2149\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8256 - val_loss: 2.1463\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8107 - val_loss: 2.0814\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7976 - val_loss: 2.0198\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7860 - val_loss: 1.9613\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7753 - val_loss: 1.9049\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7648 - val_loss: 1.8533\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7535 - val_loss: 1.8037\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7400 - val_loss: 1.7546\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7251 - val_loss: 1.7077\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7117 - val_loss: 1.6639\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7005 - val_loss: 1.6231\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6910 - val_loss: 1.5847\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6828 - val_loss: 1.5502\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6756 - val_loss: 1.5192\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6691 - val_loss: 1.4909\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6633 - val_loss: 1.4647\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6579 - val_loss: 1.4400\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6529 - val_loss: 1.4162\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6482 - val_loss: 1.3932\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6438 - val_loss: 1.3710\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6396 - val_loss: 1.3499\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6357 - val_loss: 1.3296\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 1.3101\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6283 - val_loss: 1.2913\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6249 - val_loss: 1.2732\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6215 - val_loss: 1.2556\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6184 - val_loss: 1.2389\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6153 - val_loss: 1.2228\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6124 - val_loss: 1.2075\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6095 - val_loss: 1.1941\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 1.1814\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6042 - val_loss: 1.1690\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 1.1572\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 1.1458\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 1.1348\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5946 - val_loss: 1.1241\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5923 - val_loss: 1.1139\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5902 - val_loss: 1.1039\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5882 - val_loss: 1.0942\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5862 - val_loss: 1.0848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5843 - val_loss: 1.0760\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 1.0673\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5806 - val_loss: 1.0589\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5789 - val_loss: 1.0509\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5772 - val_loss: 1.0432\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 1.0356\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5739 - val_loss: 1.0284\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 1.0215\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5709 - val_loss: 1.0147\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5695 - val_loss: 1.0082\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5681 - val_loss: 1.0020\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5667 - val_loss: 0.9961\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5654 - val_loss: 0.9902\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5641 - val_loss: 0.9847\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5629 - val_loss: 0.9794\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5617 - val_loss: 0.9745\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5605 - val_loss: 0.9699\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.9654\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5583 - val_loss: 0.9611\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5572 - val_loss: 0.9570\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5562 - val_loss: 0.9531\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5551 - val_loss: 0.9493\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5541 - val_loss: 0.9456\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.9421\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5522 - val_loss: 0.9387\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5513 - val_loss: 0.9353\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5504 - val_loss: 0.9320\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5495 - val_loss: 0.9290\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5487 - val_loss: 0.9259\n",
      "121/121 [==============================] - 0s 633us/step - loss: 0.5645\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  27.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.2812 - val_loss: 5.5818\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1629 - val_loss: 5.5128\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0208 - val_loss: 5.4268\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8524 - val_loss: 5.3233\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6552 - val_loss: 5.1900\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4281 - val_loss: 5.0309\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1707 - val_loss: 4.8406\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8854 - val_loss: 4.6253\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5760 - val_loss: 4.3721\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2481 - val_loss: 4.0766\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9129 - val_loss: 3.7676\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5871 - val_loss: 3.4360\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2849 - val_loss: 3.1002\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0130 - val_loss: 2.7767\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7742 - val_loss: 2.4760\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5770 - val_loss: 2.2194\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4242 - val_loss: 1.9987\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3093 - val_loss: 1.8190\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2245 - val_loss: 1.6845\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1617 - val_loss: 1.5830\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1149 - val_loss: 1.5013\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0792 - val_loss: 1.4312\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0508 - val_loss: 1.3704\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0271 - val_loss: 1.3164\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0061 - val_loss: 1.2679\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9867 - val_loss: 1.2242\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9680 - val_loss: 1.1830\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9494 - val_loss: 1.1490\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9300 - val_loss: 1.1161\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9096 - val_loss: 1.0835\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8881 - val_loss: 1.0512\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8670 - val_loss: 1.0212\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8482 - val_loss: 0.9942\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8319 - val_loss: 0.9721\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8180 - val_loss: 0.9537\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8061 - val_loss: 0.9376\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7960 - val_loss: 0.9231\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7871 - val_loss: 0.9097\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7790 - val_loss: 0.8972\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7714 - val_loss: 0.8853\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7638 - val_loss: 0.8734\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7555 - val_loss: 0.8607\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7454 - val_loss: 0.8454\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7317 - val_loss: 0.8268\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7153 - val_loss: 0.8073\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7004 - val_loss: 0.7908\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6886 - val_loss: 0.7772\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6792 - val_loss: 0.7657\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6716 - val_loss: 0.7557\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6652 - val_loss: 0.7469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6597 - val_loss: 0.7390\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6548 - val_loss: 0.7316\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6505 - val_loss: 0.7248\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6465 - val_loss: 0.7184\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6428 - val_loss: 0.7123\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6393 - val_loss: 0.7066\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6360 - val_loss: 0.7012\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6329 - val_loss: 0.6960\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6298 - val_loss: 0.6909\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6269 - val_loss: 0.6861\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6241 - val_loss: 0.6815\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6771\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6188 - val_loss: 0.6728\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6163 - val_loss: 0.6687\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6138 - val_loss: 0.6647\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6609\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6091 - val_loss: 0.6571\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.6535\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6047 - val_loss: 0.6501\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6025 - val_loss: 0.6467\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6435\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6404\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.6374\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5947 - val_loss: 0.6345\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5929 - val_loss: 0.6317\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5911 - val_loss: 0.6290\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5893 - val_loss: 0.6263\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5877 - val_loss: 0.6238\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5860 - val_loss: 0.6213\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.6189\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5829 - val_loss: 0.6166\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5814 - val_loss: 0.6144\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.6122\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5785 - val_loss: 0.6101\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5771 - val_loss: 0.6080\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.6061\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - val_loss: 0.6042\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.6023\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - val_loss: 0.6006\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5708 - val_loss: 0.5988\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5696 - val_loss: 0.5971\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - val_loss: 0.5955\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5940\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5662 - val_loss: 0.5924\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5652 - val_loss: 0.5910\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.5895\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5631 - val_loss: 0.5881\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5622 - val_loss: 0.5868\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5612 - val_loss: 0.5855\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - val_loss: 0.5842\n",
      "121/121 [==============================] - 0s 667us/step - loss: 0.5540\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  26.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "121/121 [==============================] - 0s 596us/step - loss: 6.5948\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   3.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 936us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 959us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "121/121 [==============================] - 0s 604us/step - loss: 6.6825\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 888us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 905us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 876us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 892us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "121/121 [==============================] - 0s 604us/step - loss: 6.2349\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.3988 - val_loss: 5.4834\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5242 - val_loss: 2.3288\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9247 - val_loss: 1.9872\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8505 - val_loss: 1.8777\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8084 - val_loss: 1.8115\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7756 - val_loss: 1.7643\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7498 - val_loss: 1.7281\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7283 - val_loss: 1.7035\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7113 - val_loss: 1.6870\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6973 - val_loss: 1.6728\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6861 - val_loss: 1.6617\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6769 - val_loss: 1.6531\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6694 - val_loss: 1.6453\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6632 - val_loss: 1.6397\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6581 - val_loss: 1.6341\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6536 - val_loss: 1.6303\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6501 - val_loss: 1.6261\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6469 - val_loss: 1.6231\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6439 - val_loss: 1.6213\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6416 - val_loss: 1.6181\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6390 - val_loss: 1.6164\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6336 - val_loss: 1.5730\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5056 - val_loss: 1.4534\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4640 - val_loss: 1.4461\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4604 - val_loss: 1.4430\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4584 - val_loss: 1.4407\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4568 - val_loss: 1.4387\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4552 - val_loss: 1.4368\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4532 - val_loss: 1.4351\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4520 - val_loss: 1.4333\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4503 - val_loss: 1.4314\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4486 - val_loss: 1.4299\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4462 - val_loss: 1.4262\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4308 - val_loss: 1.3440\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2229 - val_loss: 1.1183\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1143 - val_loss: 1.0953\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1043 - val_loss: 1.0907\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1013 - val_loss: 1.0893\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0453 - val_loss: 0.9546\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9396 - val_loss: 0.9265\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9276 - val_loss: 0.9243\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9250 - val_loss: 0.9230\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9235 - val_loss: 0.9226\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9216 - val_loss: 0.9237\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9204 - val_loss: 0.9233\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9185 - val_loss: 0.9245\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9175 - val_loss: 0.9254\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9160 - val_loss: 0.9269\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9148 - val_loss: 0.9280\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9136 - val_loss: 0.9302\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9123 - val_loss: 0.9308\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9115 - val_loss: 0.9317\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9104 - val_loss: 0.9332\n",
      "121/121 [==============================] - 0s 629us/step - loss: 0.9492\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  14.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.8849 - val_loss: 6.3966\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0258 - val_loss: 10.9438\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7725 - val_loss: 8.9159\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4686 - val_loss: 5.7752\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3365 - val_loss: 3.7998\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2841 - val_loss: 2.7009\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2465 - val_loss: 2.0147\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2184 - val_loss: 1.6322\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1980 - val_loss: 1.4288\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1833 - val_loss: 1.3165\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1721 - val_loss: 1.2752\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1637 - val_loss: 1.2451\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1573 - val_loss: 1.2221\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1523 - val_loss: 1.2104\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1480 - val_loss: 1.1974\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1445 - val_loss: 1.1915\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1415 - val_loss: 1.1831\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1391 - val_loss: 1.1790\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1365 - val_loss: 1.1747\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1345 - val_loss: 1.1718\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1326 - val_loss: 1.1681\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1307 - val_loss: 1.1666\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1289 - val_loss: 1.1654\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1273 - val_loss: 1.1638\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1258 - val_loss: 1.1640\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1243 - val_loss: 1.1644\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1227 - val_loss: 1.1664\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1214 - val_loss: 1.1659\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1196 - val_loss: 1.1717\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1191 - val_loss: 1.1707\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1175 - val_loss: 1.1716\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1162 - val_loss: 1.1744\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1152 - val_loss: 1.1788\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1140 - val_loss: 1.1831\n",
      "121/121 [==============================] - 0s 704us/step - loss: 1.1129\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  10.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 3.8791 - val_loss: 3.2635\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7637 - val_loss: 1.5819\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2960 - val_loss: 1.2776\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2251 - val_loss: 1.1825\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1826 - val_loss: 1.1301\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1482 - val_loss: 1.0914\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1195 - val_loss: 1.0627\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0956 - val_loss: 1.0365\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0750 - val_loss: 1.0170\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0578 - val_loss: 0.9994\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0426 - val_loss: 0.9849\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0298 - val_loss: 0.9728\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0193 - val_loss: 0.9639\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0103 - val_loss: 0.9569\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0024 - val_loss: 0.9519\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9957 - val_loss: 0.9481\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9897 - val_loss: 0.9478\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9844 - val_loss: 0.9491\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9801 - val_loss: 0.9504\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9759 - val_loss: 0.9537\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9722 - val_loss: 0.9566\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9687 - val_loss: 0.9613\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9657 - val_loss: 0.9628\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9627 - val_loss: 0.9687\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9598 - val_loss: 0.9652\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9555 - val_loss: 0.9622\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9080 - val_loss: 0.8420\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7937 - val_loss: 0.8139\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7813 - val_loss: 0.8195\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7786 - val_loss: 0.8136\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7762 - val_loss: 0.8150\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7740 - val_loss: 0.8220\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7719 - val_loss: 0.8210\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7697 - val_loss: 0.8300\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7683 - val_loss: 0.8236\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7663 - val_loss: 0.8183\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7648 - val_loss: 0.8123\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7630 - val_loss: 0.8237\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7604 - val_loss: 0.8251\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6598 - val_loss: 0.7022\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5877 - val_loss: 0.6929\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5826 - val_loss: 0.6733\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5801 - val_loss: 0.6472\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.6005\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4424 - val_loss: 0.5062\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4055 - val_loss: 0.4849\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4635\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3999 - val_loss: 0.4584\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4702\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3967 - val_loss: 0.4701\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4751\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.4736\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4632\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4519\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.4501\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.4539\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3872 - val_loss: 0.4677\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3864 - val_loss: 0.4642\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3849 - val_loss: 0.4619\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3837 - val_loss: 0.4453\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.4381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4464\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.4232\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3800 - val_loss: 0.4178\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.4044\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3778 - val_loss: 0.4275\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3772 - val_loss: 0.3988\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3764 - val_loss: 0.4238\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3754 - val_loss: 0.3922\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3744 - val_loss: 0.4304\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3738 - val_loss: 0.3914\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3729 - val_loss: 0.4134\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3876\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3717 - val_loss: 0.3773\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3709 - val_loss: 0.4087\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3694 - val_loss: 0.4494\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3698 - val_loss: 0.3987\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3959\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3739\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3672 - val_loss: 0.3932\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3667 - val_loss: 0.3830\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3662 - val_loss: 0.4062\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3656 - val_loss: 0.3835\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.4210\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3559\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 0.3852\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3632 - val_loss: 0.4352\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3633 - val_loss: 0.3536\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3624 - val_loss: 0.4049\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 0.3629\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.4045\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3398\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3609 - val_loss: 0.3726\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3821\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3593 - val_loss: 0.3791\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3590 - val_loss: 0.4088\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3587 - val_loss: 0.3896\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3582 - val_loss: 0.3413\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3939\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.4164\n",
      "121/121 [==============================] - 0s 617us/step - loss: 0.3518\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=  28.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9557 - val_loss: 6.3453\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8864 - val_loss: 6.1945\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8159 - val_loss: 6.0455\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7446 - val_loss: 5.8989\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6728 - val_loss: 5.7551\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 4.6009 - val_loss: 5.6141\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5290 - val_loss: 5.4765\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4575 - val_loss: 5.3425\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3867 - val_loss: 5.2125\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 4.3167 - val_loss: 5.0860\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2476 - val_loss: 4.9633\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1794 - val_loss: 4.8444\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1121 - val_loss: 4.7288\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0458 - val_loss: 4.6167\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9804 - val_loss: 4.5081\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9159 - val_loss: 4.4027\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8523 - val_loss: 4.3003\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 3.7897 - val_loss: 4.2008\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7278 - val_loss: 4.1043\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 3.6668 - val_loss: 4.0106\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 3.6067 - val_loss: 3.9197\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 3.5474 - val_loss: 3.8313\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 3.4888 - val_loss: 3.7453\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 3.4310 - val_loss: 3.6618\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 3.3739 - val_loss: 3.5805\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 3.3175 - val_loss: 3.5015\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 3.2618 - val_loss: 3.4244\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2067 - val_loss: 3.3494\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1522 - val_loss: 3.2761\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0983 - val_loss: 3.2047\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0448 - val_loss: 3.1351\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9918 - val_loss: 3.0671\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9394 - val_loss: 3.0006\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8874 - val_loss: 2.9356\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8359 - val_loss: 2.8721\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7849 - val_loss: 2.8099\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7344 - val_loss: 2.7485\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6845 - val_loss: 2.6892\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6353 - val_loss: 2.6313\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5867 - val_loss: 2.5747\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5388 - val_loss: 2.5194\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4917 - val_loss: 2.4656\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4453 - val_loss: 2.4130\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3996 - val_loss: 2.3617\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3548 - val_loss: 2.3118\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3109 - val_loss: 2.2632\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2679 - val_loss: 2.2159\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2257 - val_loss: 2.1699\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1844 - val_loss: 2.1252\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1441 - val_loss: 2.0816\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1045 - val_loss: 2.0393\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0659 - val_loss: 1.9981\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0280 - val_loss: 1.9581\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9910 - val_loss: 1.9192\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9548 - val_loss: 1.8813\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9195 - val_loss: 1.8446\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 1.8849 - val_loss: 1.8088\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8512 - val_loss: 1.7741\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 1.8183 - val_loss: 1.7403\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 1.7861 - val_loss: 1.7075\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 1.7547 - val_loss: 1.6756\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 1.7241 - val_loss: 1.6445\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 1.6942 - val_loss: 1.6144\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 1.6650 - val_loss: 1.5851\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 1.6366 - val_loss: 1.5566\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6089 - val_loss: 1.5289\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5818 - val_loss: 1.5020\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5554 - val_loss: 1.4759\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5296 - val_loss: 1.4505\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5045 - val_loss: 1.4257\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4799 - val_loss: 1.4017\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4560 - val_loss: 1.3782\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4327 - val_loss: 1.3554\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4099 - val_loss: 1.3333\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3877 - val_loss: 1.3117\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3660 - val_loss: 1.2906\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3449 - val_loss: 1.2701\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3242 - val_loss: 1.2501\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3041 - val_loss: 1.2306\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2844 - val_loss: 1.2115\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2651 - val_loss: 1.1929\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2464 - val_loss: 1.1748\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2280 - val_loss: 1.1570\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2101 - val_loss: 1.1397\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1927 - val_loss: 1.1228\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1756 - val_loss: 1.1063\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1589 - val_loss: 1.0902\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1427 - val_loss: 1.0745\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1268 - val_loss: 1.0591\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1113 - val_loss: 1.0442\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0961 - val_loss: 1.0295\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0813 - val_loss: 1.0153\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0669 - val_loss: 1.0014\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0528 - val_loss: 0.9878\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0391 - val_loss: 0.9746\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0257 - val_loss: 0.9616\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0127 - val_loss: 0.9491\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9999 - val_loss: 0.9368\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9875 - val_loss: 0.9249\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9755 - val_loss: 0.9133\n",
      "121/121 [==============================] - 0s 688us/step - loss: 0.9983\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  25.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0357 - val_loss: 6.0767\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9673 - val_loss: 5.9984\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8976 - val_loss: 5.9183\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8274 - val_loss: 5.8369\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7570 - val_loss: 5.7547\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6867 - val_loss: 5.6720\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6168 - val_loss: 5.5890\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5474 - val_loss: 5.5060\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4786 - val_loss: 5.4230\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4105 - val_loss: 5.3402\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3430 - val_loss: 5.2576\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2763 - val_loss: 5.1752\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2103 - val_loss: 5.0931\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1450 - val_loss: 5.0115\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0804 - val_loss: 4.9304\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0166 - val_loss: 4.8498\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9535 - val_loss: 4.7696\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 996us/step - loss: 3.8911 - val_loss: 4.6899\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 3.8294 - val_loss: 4.6110\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 3.7685 - val_loss: 4.5327\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1000us/step - loss: 3.7082 - val_loss: 4.4551\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 3.6486 - val_loss: 4.3782\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 3.5897 - val_loss: 4.3019\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5314 - val_loss: 4.2264\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4741 - val_loss: 4.1519\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 3.4176 - val_loss: 4.0783\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 3.3619 - val_loss: 4.0058\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3071 - val_loss: 3.9343\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2532 - val_loss: 3.8639\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2001 - val_loss: 3.7945\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1479 - val_loss: 3.7261\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0964 - val_loss: 3.6588\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0458 - val_loss: 3.5923\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9959 - val_loss: 3.5269\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9466 - val_loss: 3.4624\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8980 - val_loss: 3.3988\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8501 - val_loss: 3.3361\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 2.8027 - val_loss: 3.2743\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7560 - val_loss: 3.2134\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7099 - val_loss: 3.1534\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6644 - val_loss: 3.0942\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 2.6195 - val_loss: 3.0360\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5752 - val_loss: 2.9786\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5316 - val_loss: 2.9222\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 2.4885 - val_loss: 2.8667\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 2.4462 - val_loss: 2.8122\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4046 - val_loss: 2.7587\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3636 - val_loss: 2.7062\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3234 - val_loss: 2.6546\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2839 - val_loss: 2.6039\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2450 - val_loss: 2.5541\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2067 - val_loss: 2.5052\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1691 - val_loss: 2.4572\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 2.1322 - val_loss: 2.4100\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0958 - val_loss: 2.3636\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0600 - val_loss: 2.3179\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0248 - val_loss: 2.2730\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9900 - val_loss: 2.2286\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9556 - val_loss: 2.1848\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9216 - val_loss: 2.1415\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8880 - val_loss: 2.0990\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8550 - val_loss: 2.0573\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8225 - val_loss: 2.0163\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7906 - val_loss: 1.9761\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7593 - val_loss: 1.9367\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7286 - val_loss: 1.8981\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6986 - val_loss: 1.8603\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6692 - val_loss: 1.8234\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6404 - val_loss: 1.7872\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6123 - val_loss: 1.7519\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5848 - val_loss: 1.7173\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5580 - val_loss: 1.6836\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5317 - val_loss: 1.6505\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5061 - val_loss: 1.6183\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4811 - val_loss: 1.5867\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4566 - val_loss: 1.5558\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4327 - val_loss: 1.5257\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4094 - val_loss: 1.4963\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3866 - val_loss: 1.4676\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3644 - val_loss: 1.4396\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3427 - val_loss: 1.4122\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3215 - val_loss: 1.3855\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3008 - val_loss: 1.3595\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2805 - val_loss: 1.3341\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2607 - val_loss: 1.3094\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2414 - val_loss: 1.2852\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2226 - val_loss: 1.2617\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2042 - val_loss: 1.2389\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1862 - val_loss: 1.2166\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1687 - val_loss: 1.1949\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1516 - val_loss: 1.1738\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1349 - val_loss: 1.1533\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1186 - val_loss: 1.1332\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1027 - val_loss: 1.1137\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0872 - val_loss: 1.0947\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0721 - val_loss: 1.0762\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0573 - val_loss: 1.0582\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1000us/step - loss: 1.0430 - val_loss: 1.0407\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 1.0290 - val_loss: 1.0236\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0154 - val_loss: 1.0071\n",
      "121/121 [==============================] - 0s 612us/step - loss: 0.9994\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  25.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0381 - val_loss: 6.4086\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9699 - val_loss: 6.2633\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9007 - val_loss: 6.1193\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8309 - val_loss: 5.9774\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7610 - val_loss: 5.8382\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6914 - val_loss: 5.7020\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6221 - val_loss: 5.5687\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5533 - val_loss: 5.4385\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4852 - val_loss: 5.3117\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4177 - val_loss: 5.1881\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 4.3510 - val_loss: 5.0677\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2852 - val_loss: 4.9506\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 4.2202 - val_loss: 4.8368\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 4.1561 - val_loss: 4.7262\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 4.0930 - val_loss: 4.6190\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 4.0309 - val_loss: 4.5147\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 3.9698 - val_loss: 4.4137\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 3.9097 - val_loss: 4.3157\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 3.8505 - val_loss: 4.2206\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 3.7923 - val_loss: 4.1283\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 3.7350 - val_loss: 4.0387\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 3.6785 - val_loss: 3.9517\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 3.6228 - val_loss: 3.8673\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5680 - val_loss: 3.7852\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 3.5138 - val_loss: 3.7053\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 3.4604 - val_loss: 3.6277\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 3.4077 - val_loss: 3.5520\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 3.3556 - val_loss: 3.4784\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 3.3041 - val_loss: 3.4065\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 3.2531 - val_loss: 3.3364\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 3.2027 - val_loss: 3.2679\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 3.1526 - val_loss: 3.2009\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 3.1031 - val_loss: 3.1355\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 3.0539 - val_loss: 3.0713\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 969us/step - loss: 3.0051 - val_loss: 3.0087\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 2.9567 - val_loss: 2.9475\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 2.9086 - val_loss: 2.8875\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 2.8609 - val_loss: 2.8288\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 2.8135 - val_loss: 2.7714\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7665 - val_loss: 2.7150\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7196 - val_loss: 2.6596\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6731 - val_loss: 2.6054\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6269 - val_loss: 2.5522\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5810 - val_loss: 2.4998\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5353 - val_loss: 2.4483\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4898 - val_loss: 2.3976\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4447 - val_loss: 2.3479\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3997 - val_loss: 2.2989\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3551 - val_loss: 2.2507\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3109 - val_loss: 2.2035\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2672 - val_loss: 2.1573\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 965us/step - loss: 2.2240 - val_loss: 2.1120\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 2.1813 - val_loss: 2.0677\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 2.1393 - val_loss: 2.0244\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 2.0978 - val_loss: 1.9820\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 2.0569 - val_loss: 1.9406\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0167 - val_loss: 1.9000\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9772 - val_loss: 1.8604\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9384 - val_loss: 1.8218\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9004 - val_loss: 1.7842\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8631 - val_loss: 1.7474\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8265 - val_loss: 1.7116\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7907 - val_loss: 1.6767\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7557 - val_loss: 1.6427\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 1.7214 - val_loss: 1.6096\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6879 - val_loss: 1.5773\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6551 - val_loss: 1.5459\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6231 - val_loss: 1.5152\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5918 - val_loss: 1.4854\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5613 - val_loss: 1.4563\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5315 - val_loss: 1.4280\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5024 - val_loss: 1.4004\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4741 - val_loss: 1.3735\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4465 - val_loss: 1.3473\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4196 - val_loss: 1.3218\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3933 - val_loss: 1.2970\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 1.3678 - val_loss: 1.2728\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 1.3429 - val_loss: 1.2493\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 1.3187 - val_loss: 1.2264\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2951 - val_loss: 1.2041\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2722 - val_loss: 1.1824\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2498 - val_loss: 1.1612\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2281 - val_loss: 1.1407\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2070 - val_loss: 1.1208\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1864 - val_loss: 1.1014\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1665 - val_loss: 1.0825\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1470 - val_loss: 1.0642\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1282 - val_loss: 1.0463\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1098 - val_loss: 1.0290\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0920 - val_loss: 1.0122\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0747 - val_loss: 0.9959\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0579 - val_loss: 0.9800\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0416 - val_loss: 0.9646\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0258 - val_loss: 0.9497\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0105 - val_loss: 0.9352\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9957 - val_loss: 0.9212\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9813 - val_loss: 0.9077\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9674 - val_loss: 0.8945\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9539 - val_loss: 0.8819\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9409 - val_loss: 0.8696\n",
      "121/121 [==============================] - 0s 654us/step - loss: 0.9317\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  26.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.8381 - val_loss: 5.4428\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1096 - val_loss: 3.5711\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7395 - val_loss: 2.0507\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4758 - val_loss: 1.6638\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4183 - val_loss: 1.5232\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3802 - val_loss: 1.4427\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3492 - val_loss: 1.3815\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3227 - val_loss: 1.3389\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3007 - val_loss: 1.3072\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2820 - val_loss: 1.2799\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2665 - val_loss: 1.2591\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2535 - val_loss: 1.2429\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2428 - val_loss: 1.2293\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2339 - val_loss: 1.2201\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2268 - val_loss: 1.2111\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2207 - val_loss: 1.2058\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2159 - val_loss: 1.2005\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2117 - val_loss: 1.1971\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2076 - val_loss: 1.1948\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1595 - val_loss: 1.1301\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1340 - val_loss: 1.1264\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1302 - val_loss: 1.1260\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1275 - val_loss: 1.1250\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1249 - val_loss: 1.1265\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1232 - val_loss: 1.1268\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1208 - val_loss: 1.1277\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1176 - val_loss: 1.1194\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0684 - val_loss: 1.0667\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0262 - val_loss: 1.0113\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9799 - val_loss: 1.0018\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9739 - val_loss: 1.0009\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9718 - val_loss: 1.0021\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9702 - val_loss: 1.0054\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9685 - val_loss: 1.0073\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9672 - val_loss: 1.0065\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9658 - val_loss: 1.0107\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9644 - val_loss: 1.0022\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9631 - val_loss: 1.0095\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9616 - val_loss: 1.0044\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9605 - val_loss: 1.0094\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9593 - val_loss: 1.0083\n",
      "121/121 [==============================] - 0s 700us/step - loss: 0.9975\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  13.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7925 - val_loss: 6.1552\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4645 - val_loss: 9.5830\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3790 - val_loss: 6.5838\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2592 - val_loss: 4.2718\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2062 - val_loss: 3.1912\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1676 - val_loss: 2.5938\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1043 - val_loss: 2.1287\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0424 - val_loss: 1.8633\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0193 - val_loss: 1.6902\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0017 - val_loss: 1.5626\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9871 - val_loss: 1.4733\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9755 - val_loss: 1.4084\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9666 - val_loss: 1.3633\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9594 - val_loss: 1.3389\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9533 - val_loss: 1.3078\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9484 - val_loss: 1.2949\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9443 - val_loss: 1.2760\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9410 - val_loss: 1.2664\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9375 - val_loss: 1.2571\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9350 - val_loss: 1.2540\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9326 - val_loss: 1.2458\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9301 - val_loss: 1.2459\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9279 - val_loss: 1.2465\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9259 - val_loss: 1.2437\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9241 - val_loss: 1.2436\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9222 - val_loss: 1.2456\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9203 - val_loss: 1.2501\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9189 - val_loss: 1.2507\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9166 - val_loss: 1.2635\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9162 - val_loss: 1.2612\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9143 - val_loss: 1.2605\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9129 - val_loss: 1.2706\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9116 - val_loss: 1.2829\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9103 - val_loss: 1.2964\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9091 - val_loss: 1.3074\n",
      "121/121 [==============================] - 0s 658us/step - loss: 0.9187\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  11.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0825 - val_loss: 4.8995\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3136 - val_loss: 3.4637\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4864 - val_loss: 1.7097\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1082 - val_loss: 1.2978\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0387 - val_loss: 1.1463\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9940 - val_loss: 1.0611\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9577 - val_loss: 0.9998\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9276 - val_loss: 0.9489\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9017 - val_loss: 0.9152\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8806 - val_loss: 0.8868\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8627 - val_loss: 0.8647\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8482 - val_loss: 0.8474\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8368 - val_loss: 0.8342\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8274 - val_loss: 0.8248\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8196 - val_loss: 0.8176\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8133 - val_loss: 0.8120\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8076 - val_loss: 0.8099\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8028 - val_loss: 0.8084\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7989 - val_loss: 0.8088\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7952 - val_loss: 0.8121\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7919 - val_loss: 0.8169\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7889 - val_loss: 0.8231\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7864 - val_loss: 0.8265\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7839 - val_loss: 0.8364\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7818 - val_loss: 0.8343\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7796 - val_loss: 0.8332\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7780 - val_loss: 0.8429\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7761 - val_loss: 0.8401\n",
      "121/121 [==============================] - 0s 633us/step - loss: 0.7614\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=   8.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0529 - val_loss: 5.5475\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4855 - val_loss: 4.3356\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0639 - val_loss: 2.2284\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6627 - val_loss: 1.7104\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5510 - val_loss: 1.5879\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4680 - val_loss: 1.4727\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4199 - val_loss: 1.4225\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3937 - val_loss: 1.3894\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3730 - val_loss: 1.3649\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3555 - val_loss: 1.3439\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3412 - val_loss: 1.3274\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3289 - val_loss: 1.3141\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3187 - val_loss: 1.3024\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3102 - val_loss: 1.2940\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3030 - val_loss: 1.2850\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2966 - val_loss: 1.2793\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2914 - val_loss: 1.2733\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2868 - val_loss: 1.2693\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2824 - val_loss: 1.2671\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2513 - val_loss: 1.2097\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2145 - val_loss: 1.2021\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2096 - val_loss: 1.2001\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2067 - val_loss: 1.1979\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2040 - val_loss: 1.1978\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2023 - val_loss: 1.1968\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2000 - val_loss: 1.1963\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1981 - val_loss: 1.1959\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1964 - val_loss: 1.1956\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1941 - val_loss: 1.1954\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1928 - val_loss: 1.1958\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1913 - val_loss: 1.1954\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1896 - val_loss: 1.1962\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1881 - val_loss: 1.1961\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1866 - val_loss: 1.1959\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1853 - val_loss: 1.1971\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1839 - val_loss: 1.2005\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1826 - val_loss: 1.1998\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1814 - val_loss: 1.2036\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1800 - val_loss: 1.2041\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1790 - val_loss: 1.2090\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1779 - val_loss: 1.2102\n",
      "121/121 [==============================] - 0s 679us/step - loss: 1.2222\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  12.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.1289 - val_loss: 5.5364\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6807 - val_loss: 8.2559\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2607 - val_loss: 8.0480\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8978 - val_loss: 5.6237\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7824 - val_loss: 3.9766\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7406 - val_loss: 3.0674\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7089 - val_loss: 2.5916\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6825 - val_loss: 2.3477\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6604 - val_loss: 2.1885\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6420 - val_loss: 2.0745\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6264 - val_loss: 1.9974\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6136 - val_loss: 1.9367\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6029 - val_loss: 1.8907\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5940 - val_loss: 1.8642\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5864 - val_loss: 1.8360\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5800 - val_loss: 1.8215\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5746 - val_loss: 1.8045\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5703 - val_loss: 1.7964\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5662 - val_loss: 1.7884\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5630 - val_loss: 1.7849\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5602 - val_loss: 1.7799\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5572 - val_loss: 1.7788\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5123 - val_loss: 1.7305\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4889 - val_loss: 1.7297\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4858 - val_loss: 1.7329\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4838 - val_loss: 1.7391\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4818 - val_loss: 1.7471\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4802 - val_loss: 1.7519\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4779 - val_loss: 1.7694\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4772 - val_loss: 1.7720\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4754 - val_loss: 1.7769\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4739 - val_loss: 1.7883\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4726 - val_loss: 1.8007\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4713 - val_loss: 1.8166\n",
      "121/121 [==============================] - 0s 687us/step - loss: 1.4692\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  10.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0942 - val_loss: 4.7395\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1548 - val_loss: 3.3544\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6979 - val_loss: 2.0430\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4493 - val_loss: 1.7021\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3724 - val_loss: 1.5475\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3324 - val_loss: 1.4436\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3009 - val_loss: 1.3800\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2755 - val_loss: 1.3241\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2541 - val_loss: 1.2883\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2373 - val_loss: 1.2586\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2234 - val_loss: 1.2350\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2123 - val_loss: 1.2163\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2037 - val_loss: 1.2020\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1964 - val_loss: 1.1907\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1902 - val_loss: 1.1805\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1852 - val_loss: 1.1712\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1507 - val_loss: 1.1089\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1131 - val_loss: 1.0988\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1083 - val_loss: 1.0933\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1051 - val_loss: 1.0890\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1023 - val_loss: 1.0859\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0996 - val_loss: 1.0844\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0975 - val_loss: 1.0826\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0953 - val_loss: 1.0832\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0936 - val_loss: 1.0806\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0690 - val_loss: 1.0277\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0275 - val_loss: 1.0173\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0230 - val_loss: 1.0174\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0211 - val_loss: 1.0202\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0200 - val_loss: 1.0173\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0186 - val_loss: 1.0184\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0171 - val_loss: 1.0190\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0158 - val_loss: 1.0178\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0142 - val_loss: 1.0222\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0134 - val_loss: 1.0187\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0119 - val_loss: 1.0173\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0110 - val_loss: 1.0152\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0099 - val_loss: 1.0147\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0085 - val_loss: 1.0137\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0074 - val_loss: 1.0120\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0061 - val_loss: 1.0138\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0053 - val_loss: 1.0126\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0039 - val_loss: 1.0069\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0033 - val_loss: 1.0060\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0020 - val_loss: 1.0053\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0011 - val_loss: 1.0026\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9997 - val_loss: 0.9980\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9991 - val_loss: 0.9969\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9976 - val_loss: 0.9986\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9968 - val_loss: 0.9986\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9954 - val_loss: 1.0090\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9944 - val_loss: 0.9972\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9475 - val_loss: 0.9338\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9282 - val_loss: 0.9224\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9255 - val_loss: 0.9222\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9237 - val_loss: 0.9191\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8793 - val_loss: 0.8765\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8587 - val_loss: 0.8715\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8561 - val_loss: 0.8705\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8549 - val_loss: 0.8620\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8538 - val_loss: 0.8612\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8529 - val_loss: 0.8667\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8523 - val_loss: 0.8576\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8513 - val_loss: 0.8561\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8504 - val_loss: 0.8504\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8493 - val_loss: 0.8593\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8488 - val_loss: 0.8453\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8480 - val_loss: 0.8569\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8471 - val_loss: 0.8438\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8463 - val_loss: 0.8549\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8457 - val_loss: 0.8421\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8450 - val_loss: 0.8504\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8442 - val_loss: 0.8428\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8438 - val_loss: 0.8359\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8432 - val_loss: 0.8461\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8420 - val_loss: 0.8692\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8420 - val_loss: 0.8490\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8408 - val_loss: 0.8428\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8407 - val_loss: 0.8352\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8398 - val_loss: 0.8396\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8395 - val_loss: 0.8355\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8389 - val_loss: 0.8420\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8382 - val_loss: 0.8390\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8376 - val_loss: 0.8499\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8370 - val_loss: 0.8259\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8367 - val_loss: 0.8334\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8361 - val_loss: 0.8616\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8357 - val_loss: 0.8280\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8351 - val_loss: 0.8433\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8345 - val_loss: 0.8293\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8338 - val_loss: 0.8510\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8339 - val_loss: 0.8096\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8333 - val_loss: 0.8345\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8327 - val_loss: 0.8363\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8320 - val_loss: 0.8324\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8316 - val_loss: 0.8520\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8312 - val_loss: 0.8498\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8308 - val_loss: 0.8087\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8304 - val_loss: 0.8415\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8301 - val_loss: 0.8553\n",
      "121/121 [==============================] - 0s 671us/step - loss: 0.8135\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  30.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.0845 - val_loss: 5.4023\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6500 - val_loss: 5.1926\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0749 - val_loss: 4.8358\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3970 - val_loss: 4.2011\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6987 - val_loss: 3.3543\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0911 - val_loss: 2.6395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6736 - val_loss: 2.1156\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4360 - val_loss: 1.7796\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3053 - val_loss: 1.5589\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2243 - val_loss: 1.4108\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1668 - val_loss: 1.3007\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1208 - val_loss: 1.2201\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0790 - val_loss: 1.1513\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0321 - val_loss: 1.0733\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9798 - val_loss: 1.0202\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9507 - val_loss: 0.9851\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9323 - val_loss: 0.9602\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9184 - val_loss: 0.9401\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9067 - val_loss: 0.9227\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8958 - val_loss: 0.9065\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8836 - val_loss: 0.8872\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8495 - val_loss: 0.8346\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8099 - val_loss: 0.8058\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7912 - val_loss: 0.7903\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7810 - val_loss: 0.7798\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7738 - val_loss: 0.7716\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7681 - val_loss: 0.7647\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7632 - val_loss: 0.7586\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7587 - val_loss: 0.7530\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7547 - val_loss: 0.7481\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7510 - val_loss: 0.7437\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7476 - val_loss: 0.7397\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7444 - val_loss: 0.7359\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7415 - val_loss: 0.7325\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7388 - val_loss: 0.7294\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7364 - val_loss: 0.7267\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7341 - val_loss: 0.7240\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7320 - val_loss: 0.7218\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7300 - val_loss: 0.7196\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7283 - val_loss: 0.7179\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7265 - val_loss: 0.7163\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7250 - val_loss: 0.7149\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7235 - val_loss: 0.7135\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7221 - val_loss: 0.7123\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7209 - val_loss: 0.7113\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7196 - val_loss: 0.7105\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7185 - val_loss: 0.7096\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7174 - val_loss: 0.7090\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7164 - val_loss: 0.7084\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7155 - val_loss: 0.7078\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7146 - val_loss: 0.7075\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7137 - val_loss: 0.7071\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7129 - val_loss: 0.7069\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7121 - val_loss: 0.7067\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7113 - val_loss: 0.7066\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7106 - val_loss: 0.7064\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7099 - val_loss: 0.7065\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7093 - val_loss: 0.7064\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7087 - val_loss: 0.7065\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7080 - val_loss: 0.7068\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7075 - val_loss: 0.7071\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7069 - val_loss: 0.7077\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7064 - val_loss: 0.7081\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7059 - val_loss: 0.7085\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7053 - val_loss: 0.7089\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7049 - val_loss: 0.7091\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7043 - val_loss: 0.7096\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7038 - val_loss: 0.7100\n",
      "121/121 [==============================] - 0s 608us/step - loss: 0.7201\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  18.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.0000 - val_loss: 5.7496\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3290 - val_loss: 5.9056\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4176 - val_loss: 6.1373\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4867 - val_loss: 6.3334\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7971 - val_loss: 6.2902\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4363 - val_loss: 5.9640\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2605 - val_loss: 5.4258\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1335 - val_loss: 4.9150\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0468 - val_loss: 4.4411\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9888 - val_loss: 4.0248\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9486 - val_loss: 3.6560\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9197 - val_loss: 3.3389\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8971 - val_loss: 3.0757\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8781 - val_loss: 2.8490\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8614 - val_loss: 2.6441\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8458 - val_loss: 2.4649\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8289 - val_loss: 2.2994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8037 - val_loss: 2.1412\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7696 - val_loss: 2.0081\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7412 - val_loss: 1.9035\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7237 - val_loss: 1.8150\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7126 - val_loss: 1.7407\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7043 - val_loss: 1.6746\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6975 - val_loss: 1.6151\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6916 - val_loss: 1.5621\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6863 - val_loss: 1.5146\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6816 - val_loss: 1.4728\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6772 - val_loss: 1.4338\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6731 - val_loss: 1.4015\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6696 - val_loss: 1.3694\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6662 - val_loss: 1.3408\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6630 - val_loss: 1.3164\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6601 - val_loss: 1.2943\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6574 - val_loss: 1.2751\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6548 - val_loss: 1.2577\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6524 - val_loss: 1.2406\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6502 - val_loss: 1.2266\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6480 - val_loss: 1.2126\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6461 - val_loss: 1.2013\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6442 - val_loss: 1.1913\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6425 - val_loss: 1.1824\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6408 - val_loss: 1.1747\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6393 - val_loss: 1.1665\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6378 - val_loss: 1.1607\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6364 - val_loss: 1.1556\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6352 - val_loss: 1.1501\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6339 - val_loss: 1.1466\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6327 - val_loss: 1.1446\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6317 - val_loss: 1.1433\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6306 - val_loss: 1.1419\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6295 - val_loss: 1.1403\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6286 - val_loss: 1.1413\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6277 - val_loss: 1.1415\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6267 - val_loss: 1.1426\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6259 - val_loss: 1.1442\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6251 - val_loss: 1.1461\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 1.1474\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 1.1507\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6227 - val_loss: 1.1536\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6219 - val_loss: 1.1555\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6213 - val_loss: 1.1602\n",
      "121/121 [==============================] - 0s 625us/step - loss: 0.6388\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  16.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.0445 - val_loss: 5.3864\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3930 - val_loss: 4.8884\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5717 - val_loss: 4.2066\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7880 - val_loss: 3.5069\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2027 - val_loss: 2.8294\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8191 - val_loss: 2.2985\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5322 - val_loss: 1.8931\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3246 - val_loss: 1.6117\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2047 - val_loss: 1.4361\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1241 - val_loss: 1.3154\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0535 - val_loss: 1.2058\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9855 - val_loss: 1.1086\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9204 - val_loss: 1.0207\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8577 - val_loss: 0.9524\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8189 - val_loss: 0.9083\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7954 - val_loss: 0.8766\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7782 - val_loss: 0.8516\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7639 - val_loss: 0.8299\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7493 - val_loss: 0.8004\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7043 - val_loss: 0.7399\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6634 - val_loss: 0.7078\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6438 - val_loss: 0.6889\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6323 - val_loss: 0.6752\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6239 - val_loss: 0.6641\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6169 - val_loss: 0.6543\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6107 - val_loss: 0.6457\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6052 - val_loss: 0.6379\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6309\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5955 - val_loss: 0.6248\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5913 - val_loss: 0.6189\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5874 - val_loss: 0.6138\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5837 - val_loss: 0.6092\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5804 - val_loss: 0.6050\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5773 - val_loss: 0.6014\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5744 - val_loss: 0.5979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.5947\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5692 - val_loss: 0.5918\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - val_loss: 0.5891\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - val_loss: 0.5867\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5624 - val_loss: 0.5847\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - val_loss: 0.5829\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 0.5811\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - val_loss: 0.5793\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5549 - val_loss: 0.5776\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5530 - val_loss: 0.5759\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5510 - val_loss: 0.5741\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5485 - val_loss: 0.5712\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5430 - val_loss: 0.5633\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.5376\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4934 - val_loss: 0.5100\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.4984\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4943\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4601 - val_loss: 0.4925\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4577 - val_loss: 0.4917\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.4915\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4916\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4532 - val_loss: 0.4920\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4521 - val_loss: 0.4925\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4929\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.4934\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4942\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4482 - val_loss: 0.4952\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4956\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4466 - val_loss: 0.4961\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4459 - val_loss: 0.4965\n",
      "121/121 [==============================] - 0s 600us/step - loss: 0.4388\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  17.0s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.5984 - val_loss: 0.5131\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 874us/step - loss: 0.5313 - val_loss: 0.4713\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.5058 - val_loss: 0.4545\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.4921 - val_loss: 0.4536\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.4883 - val_loss: 0.4403\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 867us/step - loss: 0.4798 - val_loss: 0.4407\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.4799 - val_loss: 0.4367\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.4777 - val_loss: 0.4350\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 863us/step - loss: 0.4747 - val_loss: 0.4384\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.4750 - val_loss: 0.4327\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.4736 - val_loss: 0.4321\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4730 - val_loss: 0.4322\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.4733 - val_loss: 0.4316\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.4743 - val_loss: 0.4320\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4729 - val_loss: 0.4319\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.4730 - val_loss: 0.4310\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.4725 - val_loss: 0.4312\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.4739 - val_loss: 0.4311\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.4725 - val_loss: 0.4318\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4740 - val_loss: 0.4319\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.4727 - val_loss: 0.4317\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.4730 - val_loss: 0.4315\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.4732 - val_loss: 0.4312\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.4718 - val_loss: 0.4323\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4704 - val_loss: 0.4348\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 866us/step - loss: 0.4718 - val_loss: 0.4320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000293DE4ABE20&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000293DE4ABE20&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000293DE4ABE20&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x00000293DE4ABE20&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000293DE4ABE20>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(ker_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac102b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 4, 'n_hidden': 1, 'learning_rate': 0.022174573948353458}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d92df54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa40200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cc2eb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 624us/step - loss: 0.4648\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.46476876735687256"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456a305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
